{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02428b8",
   "metadata": {},
   "source": [
    "# I. Data Preprocessing\n",
    "## Text Encoding\n",
    "### ELMo tokens embedding\n",
    "做 iDList2Sent 將句子分割成 tokens，同時將句子字數傳入 tf2_hub pretrained的 ELMo 函式。在輸出 tokens 上做 reduce mean，以得到一個句子一個embedding，做到降維和處理不同長度的句子。\n",
    "原本打算以圖片為主軸做 encoding，每張圖片的輸出檔 size 是 (這張圖片的句子數量，20，1024)；後來決定以句子為主軸，針對每個句子做 embedding 並存下該句子對應的圖片，這樣每個句子都會運用到，並且每張圖片會被用到多次。最後做好 embedding 的檔案以 npy 檔儲存。\n",
    "\n",
    "### Sentence BERT sentence embedding\n",
    "通過 pretrained 的 sentence BERT 做句子的 encoding。與 ELMo 比較不同的部份是，他對每一句話的輸出是一個 1 x 384 的向量，而不是每個字都有自己的向量，因此可以直接使用，不需要經過降維處理，在訓練上也能讓我們的generator生出對應顏色的圖片，但最後 train 出來的圖片都長一樣，可能是有其他的參數要調整，但最後沒有成功做出來。\n",
    "\n",
    "## Image Preprocessing\n",
    "1. resize_with_crop_or_pad\n",
    "裁切或填補圖片達到目標長寬。\n",
    "\n",
    "2. random_flip_left_right\n",
    "對原本圖片做水平翻轉。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2244e",
   "metadata": {},
   "source": [
    "# II. What kind of models you have tried and how did they work\n",
    "## DCGAN\n",
    "在loss中增加了wgan-gp的gradient penalty，以及使用wrong-image增加text embedding與圖片對應的關係。經過了長時間的調整參數，最後train出的圖片一樣會出現棋盤狀，也有明顯的mode collapse的問題。\n",
    "\n",
    "## StackGAN\n",
    "取stage-I成為我們的model架構，且使用ELMo作text embedding，但是經過幾次調整參數，最後train出來的圖片一樣會出現mode collapse的問題。在我們的實驗中StackGAN在一開始就可以看出模型的好壞，有時候會出現全部黑色的情況，在後來的階段出現顏色時，會出現嚴重的mode collapse（全部的敘述都產出相同的圖片）。\n",
    "\n",
    "## Improve-WGAN\n",
    "與DCGAN和StackGAN相同，在loss計算我們起初也把wrong image考慮進去，但後來我們將wrong image從loss拔除，拔除後在訓練時能夠更穩定，但是圖片依然會出現mode collapse的問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08966afe",
   "metadata": {},
   "source": [
    "# III. What problems occurred and how did you solve them\n",
    "1. 在我們訓練 ELMo + Improve-WGAN 的過程中，其實也有不斷發生mode collapse的問題，因此在訓練過程中，我們需要頻繁的讓模型停止訓練並對參數進行調整。除此之外，有時也會發生一樣的參數有時能train起來，有時會失敗的問題，對於這種情況，我們的解決方法就是多試幾次後，再調整訓練參數\n",
    "\n",
    "2. 最初我們使用 lab14 的 5 * WD、1 * WG 架構去訓練模型，Discriminator 的 loss 降低得極為迅速，而 Generator 則一直維持非常高的 loss。所以判斷說 Discriminator訓練的太強，Generator 完全跟不上，後來我們不斷地調整兩者的比例，最後以2 * WD、1 * WG 的架構訓練出最後的模型。\n",
    "\n",
    "3. 除了使用 ELMO 和 Sentence BERT 以外，我們也有使用像是 ALBERT 等 pretrained 好的語言模型。我們之所以選擇 ALBERT 的原因是他在許多語意理解的 NLP Benchmark 是排名比較前面的，因此我們認為他對於抓取句子中的花朵顏色等資訊會是比較好的。但最後我們發現不管重複訓練多少次，使用 ALBERT 加上不同的模型架構，Generator 所生出的花顏色都不符合預期，因此捨棄 ALBERT 改為使用其他模型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046de5f",
   "metadata": {},
   "source": [
    "# IV. Pick 5 descriptions from testing data and generate 5 image with different noise z respectively\n",
    "\n",
    "## inference_0876.jpg\n",
    "white petals that become yellow as they go to the center where there is an orange stamen\n",
    "![](https://imgur.com/Vt63Nsq.png)\n",
    "\n",
    "## inference_0023.jpg\n",
    "flower with white long white petals and very long purple stamen\n",
    "![](https://imgur.com/xrvULdY.png)\n",
    "\n",
    "## inference_1725.jpg\n",
    "this flower has petals that are red with yellow stigma\n",
    "![](https://imgur.com/7ru4U0z.png)\n",
    "\n",
    "## inference_3719.jpg\n",
    "five white petals yellow centers are arranged around six pistils\n",
    "![](https://imgur.com/a59ZpaN.png)\n",
    "\n",
    "## inference_3940.jpg\n",
    "the flower has round edged petals that are purple with white stamen\n",
    "![](https://imgur.com/OIjL57G.png)\n",
    "\n",
    "\n",
    "## We Generate the image from five sentences, with different noize z\n",
    "![](https://imgur.com/WppQxMr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a235876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
