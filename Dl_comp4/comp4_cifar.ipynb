{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdc2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "from IPython import display\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64e4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a58497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 00:32:05.140741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-20 00:32:06.024298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1c:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890db95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/michael1017/work/data/comp4/cifar/origin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97a0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(base_path + 'x_train_cifar10_unlearn.npy')\n",
    "# x_train = high_pass_filtered(x_train)\n",
    "y_train = np.load(base_path + 'y_train_cifar10.npy')\n",
    "x_val = np.load(base_path + 'x_val_cifar10.npy')\n",
    "# x_val = high_pass_filtered(x_val)\n",
    "y_val = np.load(base_path + 'y_val_cifar10.npy')\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310798c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b3eeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc7d84700a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc6dda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=25>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape = (), minval=25, maxval=33, dtype=tf.int32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670e04a",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baee346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_generator(x_train, y_train):\n",
    "    \n",
    "    #random crop image from 24*24*3 to 32*32*3 and resize it \n",
    "    rand_int = tf.random.uniform(shape = (), minval=24, maxval=33, dtype=tf.int32, seed=None, name=None)\n",
    "    gray_img = tf.image.random_crop(x_train,(rand_int, rand_int,3))\n",
    "    gray_img = tf.image.resize(gray_img, (32,32))\n",
    "    \n",
    "    #random flip left right\n",
    "    gray_img = tf.image.random_flip_left_right(gray_img)\n",
    "\n",
    "    gray_img = tf.image.random_contrast(gray_img, lower = 0.2, upper = 1.8)\n",
    "    gray_img = tf.image.random_hue(gray_img,max_delta=0.5)\n",
    "    gray_img = tf.image.random_saturation(gray_img, lower = 0.2, upper = 1.8)\n",
    "    \n",
    "    #random translate dx dy from -10 ~ 10 (0.2% acc would translate img)\n",
    "    dx = tf.random.uniform(shape = (), minval=-10, maxval=11, dtype=tf.int32, seed=None, name=None)\n",
    "    dy = tf.random.uniform(shape = (), minval=-10, maxval=11, dtype=tf.int32, seed=None, name=None)\n",
    "    if(tf.random.uniform(shape = (), minval=0, maxval=1, dtype=tf.float32) >= 0.8):\n",
    "        gray_img = tfa.image.translate(images=gray_img,translations=[dx, dy]) \n",
    "\n",
    "    return gray_img, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce42990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(training_data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(x_train.shape[0])\n",
    "batched_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.shuffle(x_val.shape[0])\n",
    "batched_val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cc9000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 00:32:08.150101: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1657] (One-time warning): Not using XLA:CPU for cluster.\n",
      "\n",
      "If you want XLA:CPU, do one of the following:\n",
      "\n",
      " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
      " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
      " - use experimental_jit_scope, or\n",
      " - use tf.function(jit_compile=True).\n",
      "\n",
      "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
      "proper command-line flag, not via TF_XLA_FLAGS).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in batched_dataset.take(1):\n",
    "    plt.imshow(data[0][50])\n",
    "    print(data[1][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4aac93",
   "metadata": {},
   "source": [
    "## Model(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13db273b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,447,434\n",
      "Trainable params: 16,447,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='vgg16')\n",
    "model.add(Conv2D(input_shape=(32,32,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "# model.add(AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc279b9",
   "metadata": {},
   "source": [
    "## [Important] you should change your check point direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7cd2211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-32GB, compute capability 7.0\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/home/michael1017/jinyu/comp4/ckpt2',            ### !!! chage it\n",
    "    save_weights_only=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    ")\n",
    "callbacks = [\n",
    "    model_checkpoint_callback,\n",
    "    tf.keras.callbacks.EarlyStopping(patience=150, monitor = 'val_acc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcac001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 00:32:14.193679: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x7fc70c00bd50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-20 00:32:14.193728: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2022-01-20 00:32:14.209247: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-01-20 00:32:15.033358: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/625 [..............................] - ETA: 8s - loss: 2.3026 - acc: 0.1111    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 00:32:18.797024: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 2.1897 - acc: 0.1574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 00:32:29.913866: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 20s 20ms/step - loss: 2.1897 - acc: 0.1574 - val_loss: 1.9476 - val_acc: 0.2511\n",
      "Epoch 2/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.9813 - acc: 0.2581INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.9813 - acc: 0.2581 - val_loss: 1.8263 - val_acc: 0.3285\n",
      "Epoch 3/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.8501 - acc: 0.3114INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.8501 - acc: 0.3114 - val_loss: 1.6198 - val_acc: 0.3987\n",
      "Epoch 4/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.7110 - acc: 0.3683INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 1.7110 - acc: 0.3683 - val_loss: 1.4822 - val_acc: 0.4550\n",
      "Epoch 5/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.5734 - acc: 0.4258INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.5734 - acc: 0.4258 - val_loss: 1.4239 - val_acc: 0.4797\n",
      "Epoch 6/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.4654 - acc: 0.4664INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.4651 - acc: 0.4665 - val_loss: 1.2972 - val_acc: 0.5326\n",
      "Epoch 7/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 1.3654 - acc: 0.5050INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.3658 - acc: 0.5048 - val_loss: 1.2314 - val_acc: 0.5589\n",
      "Epoch 8/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.2991 - acc: 0.5339INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.2991 - acc: 0.5339 - val_loss: 1.2359 - val_acc: 0.5669\n",
      "Epoch 9/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2310 - acc: 0.5593INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.2311 - acc: 0.5592 - val_loss: 1.0928 - val_acc: 0.6095\n",
      "Epoch 10/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.1854 - acc: 0.5779INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.1854 - acc: 0.5779 - val_loss: 1.0320 - val_acc: 0.6318\n",
      "Epoch 11/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.1245 - acc: 0.5981INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 1.1244 - acc: 0.5981 - val_loss: 1.0283 - val_acc: 0.6450\n",
      "Epoch 12/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.0813 - acc: 0.6160INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.0813 - acc: 0.6160 - val_loss: 0.9936 - val_acc: 0.6497\n",
      "Epoch 13/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.0481 - acc: 0.6296INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 1.0479 - acc: 0.6296 - val_loss: 0.9490 - val_acc: 0.6728\n",
      "Epoch 14/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 1.0105 - acc: 0.6435 - val_loss: 0.9407 - val_acc: 0.6709\n",
      "Epoch 15/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.9767 - acc: 0.6562INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.9767 - acc: 0.6562 - val_loss: 0.9708 - val_acc: 0.6758\n",
      "Epoch 16/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.9447 - acc: 0.6680INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.9447 - acc: 0.6680 - val_loss: 0.9417 - val_acc: 0.6759\n",
      "Epoch 17/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.9112 - acc: 0.6818INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.9114 - acc: 0.6818 - val_loss: 0.9769 - val_acc: 0.6769\n",
      "Epoch 18/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8815 - acc: 0.6951INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.8815 - acc: 0.6951 - val_loss: 0.9005 - val_acc: 0.6927\n",
      "Epoch 19/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8617 - acc: 0.7031INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.8617 - acc: 0.7031 - val_loss: 0.8419 - val_acc: 0.7097\n",
      "Epoch 20/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8330 - acc: 0.7116INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.8330 - acc: 0.7116 - val_loss: 0.8395 - val_acc: 0.7211\n",
      "Epoch 21/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.8243 - acc: 0.7159 - val_loss: 0.8412 - val_acc: 0.7175\n",
      "Epoch 22/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7975 - acc: 0.7248INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.7975 - acc: 0.7248 - val_loss: 0.8080 - val_acc: 0.7303\n",
      "Epoch 23/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.7777 - acc: 0.7318 - val_loss: 0.8512 - val_acc: 0.7222\n",
      "Epoch 24/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.7578 - acc: 0.7399 - val_loss: 0.8280 - val_acc: 0.7222\n",
      "Epoch 25/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7379 - acc: 0.7458INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.7379 - acc: 0.7458 - val_loss: 0.8196 - val_acc: 0.7338\n",
      "Epoch 26/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7187 - acc: 0.7555INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.7187 - acc: 0.7554 - val_loss: 0.7953 - val_acc: 0.7350\n",
      "Epoch 27/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7021 - acc: 0.7607INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.7022 - acc: 0.7607 - val_loss: 0.7645 - val_acc: 0.7469\n",
      "Epoch 28/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.6852 - acc: 0.7664 - val_loss: 0.7949 - val_acc: 0.7394\n",
      "Epoch 29/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6668 - acc: 0.7699INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.6668 - acc: 0.7699 - val_loss: 0.7691 - val_acc: 0.7509\n",
      "Epoch 30/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6504 - acc: 0.7778INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.6504 - acc: 0.7778 - val_loss: 0.7225 - val_acc: 0.7613\n",
      "Epoch 31/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.6336 - acc: 0.7842 - val_loss: 0.8415 - val_acc: 0.7392\n",
      "Epoch 32/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6216 - acc: 0.7868INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.6216 - acc: 0.7868 - val_loss: 0.7281 - val_acc: 0.7639\n",
      "Epoch 33/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6082 - acc: 0.7921INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.6080 - acc: 0.7922 - val_loss: 0.7162 - val_acc: 0.7716\n",
      "Epoch 34/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.5893 - acc: 0.8002 - val_loss: 0.7518 - val_acc: 0.7539\n",
      "Epoch 35/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.5781 - acc: 0.8054 - val_loss: 0.7487 - val_acc: 0.7635\n",
      "Epoch 36/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.5609 - acc: 0.8095 - val_loss: 0.7679 - val_acc: 0.7594\n",
      "Epoch 37/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5538 - acc: 0.8099INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.5538 - acc: 0.8099 - val_loss: 0.7131 - val_acc: 0.7721\n",
      "Epoch 38/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.5419 - acc: 0.8172 - val_loss: 0.7152 - val_acc: 0.7695\n",
      "Epoch 39/2000\n",
      "625/625 [==============================] - 13s 16ms/step - loss: 0.5336 - acc: 0.8195 - val_loss: 0.7605 - val_acc: 0.7702\n",
      "Epoch 40/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.5195 - acc: 0.8241 - val_loss: 0.7536 - val_acc: 0.7681\n",
      "Epoch 41/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5079 - acc: 0.8305INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.5083 - acc: 0.8304 - val_loss: 0.7067 - val_acc: 0.7806\n",
      "Epoch 42/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4961 - acc: 0.8328 - val_loss: 0.7290 - val_acc: 0.7775\n",
      "Epoch 43/2000\n",
      "622/625 [============================>.] - ETA: 0s - loss: 0.4905 - acc: 0.8344INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 15s 19ms/step - loss: 0.4903 - acc: 0.8346 - val_loss: 0.7190 - val_acc: 0.7845\n",
      "Epoch 44/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4761 - acc: 0.8380INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.4761 - acc: 0.8380 - val_loss: 0.7135 - val_acc: 0.7857\n",
      "Epoch 45/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4675 - acc: 0.8412INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.4675 - acc: 0.8412 - val_loss: 0.6880 - val_acc: 0.7908\n",
      "Epoch 46/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4533 - acc: 0.8466 - val_loss: 0.7387 - val_acc: 0.7746\n",
      "Epoch 47/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4458 - acc: 0.8495 - val_loss: 0.7323 - val_acc: 0.7769\n",
      "Epoch 48/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4390 - acc: 0.8529 - val_loss: 0.7594 - val_acc: 0.7765\n",
      "Epoch 49/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4262 - acc: 0.8571 - val_loss: 0.7339 - val_acc: 0.7861\n",
      "Epoch 50/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4243 - acc: 0.8575INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.4243 - acc: 0.8575 - val_loss: 0.6846 - val_acc: 0.7937\n",
      "Epoch 51/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4152 - acc: 0.8606 - val_loss: 0.7513 - val_acc: 0.7809\n",
      "Epoch 52/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.4161 - acc: 0.8587 - val_loss: 0.7158 - val_acc: 0.7879\n",
      "Epoch 53/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3998 - acc: 0.8670INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.3998 - acc: 0.8670 - val_loss: 0.6932 - val_acc: 0.7964\n",
      "Epoch 54/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.3989 - acc: 0.8651 - val_loss: 0.7033 - val_acc: 0.7940\n",
      "Epoch 55/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.3890 - acc: 0.8694 - val_loss: 0.7202 - val_acc: 0.7913\n",
      "Epoch 56/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.3777 - acc: 0.8743 - val_loss: 0.7679 - val_acc: 0.7821\n",
      "Epoch 57/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.3765 - acc: 0.8738 - val_loss: 0.7363 - val_acc: 0.7864\n",
      "Epoch 58/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3666 - acc: 0.8786INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 15s 20ms/step - loss: 0.3664 - acc: 0.8787 - val_loss: 0.6970 - val_acc: 0.7990\n",
      "Epoch 59/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.3621 - acc: 0.8776 - val_loss: 0.7367 - val_acc: 0.7837\n",
      "Epoch 60/2000\n",
      "625/625 [==============================] - 15s 19ms/step - loss: 0.3555 - acc: 0.8806 - val_loss: 0.7722 - val_acc: 0.7902\n",
      "Epoch 61/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8833INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.3475 - acc: 0.8833 - val_loss: 0.7132 - val_acc: 0.8005\n",
      "Epoch 62/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3402 - acc: 0.8862INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.3402 - acc: 0.8862 - val_loss: 0.7222 - val_acc: 0.8041\n",
      "Epoch 63/2000\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.3379 - acc: 0.8869 - val_loss: 0.7128 - val_acc: 0.7978\n",
      "Epoch 64/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.3354 - acc: 0.8878 - val_loss: 0.7211 - val_acc: 0.7962\n",
      "Epoch 65/2000\n",
      "625/625 [==============================] - 19s 27ms/step - loss: 0.3315 - acc: 0.8894 - val_loss: 0.7642 - val_acc: 0.7969\n",
      "Epoch 66/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.3224 - acc: 0.8915 - val_loss: 0.7305 - val_acc: 0.7987\n",
      "Epoch 67/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.3159 - acc: 0.8929 - val_loss: 0.7924 - val_acc: 0.7984\n",
      "Epoch 68/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.3142 - acc: 0.8939 - val_loss: 0.7024 - val_acc: 0.8013\n",
      "Epoch 69/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.3059 - acc: 0.8966 - val_loss: 0.7401 - val_acc: 0.7992\n",
      "Epoch 70/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3002 - acc: 0.8998INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.3002 - acc: 0.8998 - val_loss: 0.7083 - val_acc: 0.8068\n",
      "Epoch 71/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.2986 - acc: 0.8994 - val_loss: 0.7855 - val_acc: 0.8038\n",
      "Epoch 72/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.2857 - acc: 0.9043 - val_loss: 0.7645 - val_acc: 0.8057\n",
      "Epoch 73/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9034INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.2905 - acc: 0.9035 - val_loss: 0.7554 - val_acc: 0.8130\n",
      "Epoch 74/2000\n",
      "625/625 [==============================] - 18s 25ms/step - loss: 0.2746 - acc: 0.9085 - val_loss: 0.7821 - val_acc: 0.8019\n",
      "Epoch 75/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.2854 - acc: 0.9048 - val_loss: 0.7485 - val_acc: 0.8007\n",
      "Epoch 76/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.2769 - acc: 0.9080 - val_loss: 0.6918 - val_acc: 0.8113\n",
      "Epoch 77/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.2710 - acc: 0.9096 - val_loss: 0.7632 - val_acc: 0.8039\n",
      "Epoch 78/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.2691 - acc: 0.9096 - val_loss: 0.7252 - val_acc: 0.8121\n",
      "Epoch 79/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.2660 - acc: 0.9117 - val_loss: 0.7212 - val_acc: 0.8064\n",
      "Epoch 80/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.2628 - acc: 0.9116 - val_loss: 0.7253 - val_acc: 0.8066\n",
      "Epoch 81/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.2588 - acc: 0.9134 - val_loss: 0.7488 - val_acc: 0.8126\n",
      "Epoch 82/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.2568 - acc: 0.9132 - val_loss: 0.8101 - val_acc: 0.8014\n",
      "Epoch 83/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.2469 - acc: 0.9167 - val_loss: 0.8059 - val_acc: 0.7962\n",
      "Epoch 84/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2430 - acc: 0.9179INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 32ms/step - loss: 0.2431 - acc: 0.9179 - val_loss: 0.7094 - val_acc: 0.8158\n",
      "Epoch 85/2000\n",
      "625/625 [==============================] - 16s 20ms/step - loss: 0.2422 - acc: 0.9183 - val_loss: 0.7899 - val_acc: 0.8129\n",
      "Epoch 86/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9200INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 32ms/step - loss: 0.2400 - acc: 0.9200 - val_loss: 0.7278 - val_acc: 0.8191\n",
      "Epoch 87/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.2379 - acc: 0.9213 - val_loss: 0.7745 - val_acc: 0.8165\n",
      "Epoch 88/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.2426 - acc: 0.9192 - val_loss: 0.7619 - val_acc: 0.8151\n",
      "Epoch 89/2000\n",
      "625/625 [==============================] - 21s 30ms/step - loss: 0.2341 - acc: 0.9217 - val_loss: 0.7678 - val_acc: 0.8113\n",
      "Epoch 90/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.2321 - acc: 0.9236 - val_loss: 0.7692 - val_acc: 0.8138\n",
      "Epoch 91/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.2332 - acc: 0.9226 - val_loss: 0.7896 - val_acc: 0.8090\n",
      "Epoch 92/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.2224 - acc: 0.9259 - val_loss: 0.7299 - val_acc: 0.8162\n",
      "Epoch 93/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.2257 - acc: 0.9250 - val_loss: 0.7464 - val_acc: 0.8153\n",
      "Epoch 94/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.2244 - acc: 0.9249 - val_loss: 0.8190 - val_acc: 0.8060\n",
      "Epoch 95/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.2198 - acc: 0.9257 - val_loss: 0.7246 - val_acc: 0.8189\n",
      "Epoch 96/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.2185 - acc: 0.9250 - val_loss: 0.7662 - val_acc: 0.8135\n",
      "Epoch 97/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.2133 - acc: 0.9291 - val_loss: 0.7992 - val_acc: 0.8166\n",
      "Epoch 98/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.2125 - acc: 0.9288 - val_loss: 0.7366 - val_acc: 0.8129\n",
      "Epoch 99/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.2072 - acc: 0.9299 - val_loss: 0.8424 - val_acc: 0.8158\n",
      "Epoch 100/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.2053 - acc: 0.9317 - val_loss: 0.8646 - val_acc: 0.8096\n",
      "Epoch 101/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2024 - acc: 0.9315INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.2024 - acc: 0.9315 - val_loss: 0.7453 - val_acc: 0.8201\n",
      "Epoch 102/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1994 - acc: 0.9332INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1994 - acc: 0.9332 - val_loss: 0.7538 - val_acc: 0.8250\n",
      "Epoch 103/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1959 - acc: 0.9343 - val_loss: 0.7777 - val_acc: 0.8190\n",
      "Epoch 104/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1989 - acc: 0.9336 - val_loss: 0.7879 - val_acc: 0.8238\n",
      "Epoch 105/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1970 - acc: 0.9335 - val_loss: 0.7000 - val_acc: 0.8222\n",
      "Epoch 106/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1923 - acc: 0.9358 - val_loss: 0.7829 - val_acc: 0.8172\n",
      "Epoch 107/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1940 - acc: 0.9355 - val_loss: 0.8452 - val_acc: 0.8099\n",
      "Epoch 108/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1969 - acc: 0.9329 - val_loss: 0.8159 - val_acc: 0.8222\n",
      "Epoch 109/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1895 - acc: 0.9363 - val_loss: 0.8377 - val_acc: 0.8112\n",
      "Epoch 110/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1810 - acc: 0.9397 - val_loss: 0.8036 - val_acc: 0.8218\n",
      "Epoch 111/2000\n",
      "625/625 [==============================] - 17s 22ms/step - loss: 0.1908 - acc: 0.9366 - val_loss: 0.8006 - val_acc: 0.8218\n",
      "Epoch 112/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1843 - acc: 0.9387 - val_loss: 0.7993 - val_acc: 0.8182\n",
      "Epoch 113/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1873 - acc: 0.9380 - val_loss: 0.7884 - val_acc: 0.8146\n",
      "Epoch 114/2000\n",
      "625/625 [==============================] - 23s 30ms/step - loss: 0.1801 - acc: 0.9400 - val_loss: 0.7675 - val_acc: 0.8220\n",
      "Epoch 115/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1783 - acc: 0.9400 - val_loss: 0.7610 - val_acc: 0.8201\n",
      "Epoch 116/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1832 - acc: 0.9386 - val_loss: 0.7920 - val_acc: 0.8222\n",
      "Epoch 117/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1732 - acc: 0.9427 - val_loss: 0.8191 - val_acc: 0.8177\n",
      "Epoch 118/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1784 - acc: 0.9399 - val_loss: 0.7449 - val_acc: 0.8215\n",
      "Epoch 119/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1760 - acc: 0.9403 - val_loss: 0.8004 - val_acc: 0.8189\n",
      "Epoch 120/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1733 - acc: 0.9419 - val_loss: 0.7571 - val_acc: 0.8244\n",
      "Epoch 121/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1722 - acc: 0.9436 - val_loss: 0.8068 - val_acc: 0.8229\n",
      "Epoch 122/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1702 - acc: 0.9434 - val_loss: 0.8217 - val_acc: 0.8229\n",
      "Epoch 123/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1686 - acc: 0.9447 - val_loss: 0.8210 - val_acc: 0.8232\n",
      "Epoch 124/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.1702 - acc: 0.9429 - val_loss: 0.9241 - val_acc: 0.8178\n",
      "Epoch 125/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1680 - acc: 0.9445 - val_loss: 0.7914 - val_acc: 0.8186\n",
      "Epoch 126/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9446INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.1654 - acc: 0.9446 - val_loss: 0.8379 - val_acc: 0.8259\n",
      "Epoch 127/2000\n",
      "625/625 [==============================] - 17s 24ms/step - loss: 0.1672 - acc: 0.9448 - val_loss: 0.8389 - val_acc: 0.8249\n",
      "Epoch 128/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1654 - acc: 0.9458 - val_loss: 0.8301 - val_acc: 0.8201\n",
      "Epoch 129/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1625 - acc: 0.9448 - val_loss: 0.7945 - val_acc: 0.8228\n",
      "Epoch 130/2000\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.1574 - acc: 0.9466 - val_loss: 0.8392 - val_acc: 0.8259\n",
      "Epoch 131/2000\n",
      "625/625 [==============================] - 23s 30ms/step - loss: 0.1561 - acc: 0.9477 - val_loss: 0.8068 - val_acc: 0.8216\n",
      "Epoch 132/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1614 - acc: 0.9474 - val_loss: 0.8717 - val_acc: 0.8179\n",
      "Epoch 133/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9475INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 31ms/step - loss: 0.1568 - acc: 0.9475 - val_loss: 0.7720 - val_acc: 0.8273\n",
      "Epoch 134/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1606 - acc: 0.9458 - val_loss: 0.8127 - val_acc: 0.8232\n",
      "Epoch 135/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1546 - acc: 0.9492 - val_loss: 0.8995 - val_acc: 0.8217\n",
      "Epoch 136/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1536 - acc: 0.9494 - val_loss: 0.8605 - val_acc: 0.8240\n",
      "Epoch 137/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.1502 - acc: 0.9510 - val_loss: 0.8002 - val_acc: 0.8240\n",
      "Epoch 138/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1492 - acc: 0.9502 - val_loss: 0.8485 - val_acc: 0.8184\n",
      "Epoch 139/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1501 - acc: 0.9501 - val_loss: 0.7843 - val_acc: 0.8254\n",
      "Epoch 140/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9510INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1476 - acc: 0.9510 - val_loss: 0.7803 - val_acc: 0.8276\n",
      "Epoch 141/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9505INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 32ms/step - loss: 0.1483 - acc: 0.9504 - val_loss: 0.8186 - val_acc: 0.8299\n",
      "Epoch 142/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1492 - acc: 0.9490 - val_loss: 0.8007 - val_acc: 0.8240\n",
      "Epoch 143/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9504INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 24s 33ms/step - loss: 0.1497 - acc: 0.9505 - val_loss: 0.7638 - val_acc: 0.8302\n",
      "Epoch 144/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1488 - acc: 0.9511 - val_loss: 0.7528 - val_acc: 0.8271\n",
      "Epoch 145/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1471 - acc: 0.9516 - val_loss: 0.9275 - val_acc: 0.8276\n",
      "Epoch 146/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1404 - acc: 0.9527INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 19s 26ms/step - loss: 0.1404 - acc: 0.9527 - val_loss: 0.8173 - val_acc: 0.8311\n",
      "Epoch 147/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1415 - acc: 0.9534 - val_loss: 0.8160 - val_acc: 0.8247\n",
      "Epoch 148/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1405 - acc: 0.9539INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 24s 35ms/step - loss: 0.1405 - acc: 0.9539 - val_loss: 0.7940 - val_acc: 0.8343\n",
      "Epoch 149/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1415 - acc: 0.9526 - val_loss: 0.7613 - val_acc: 0.8325\n",
      "Epoch 150/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1396 - acc: 0.9540 - val_loss: 0.7709 - val_acc: 0.8297\n",
      "Epoch 151/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1359 - acc: 0.9548 - val_loss: 0.7721 - val_acc: 0.8261\n",
      "Epoch 152/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1398 - acc: 0.9537 - val_loss: 0.7579 - val_acc: 0.8288\n",
      "Epoch 153/2000\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.1385 - acc: 0.9529 - val_loss: 0.8699 - val_acc: 0.8274\n",
      "Epoch 154/2000\n",
      "625/625 [==============================] - 17s 24ms/step - loss: 0.1387 - acc: 0.9532 - val_loss: 0.8052 - val_acc: 0.8313\n",
      "Epoch 155/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1328 - acc: 0.9564 - val_loss: 0.9075 - val_acc: 0.8318\n",
      "Epoch 156/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.9543INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1369 - acc: 0.9543 - val_loss: 0.7962 - val_acc: 0.8348\n",
      "Epoch 157/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1379 - acc: 0.9547 - val_loss: 0.7741 - val_acc: 0.8306\n",
      "Epoch 158/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1334 - acc: 0.9558 - val_loss: 0.8175 - val_acc: 0.8311\n",
      "Epoch 159/2000\n",
      "622/625 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9560INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1336 - acc: 0.9559 - val_loss: 0.7963 - val_acc: 0.8350\n",
      "Epoch 160/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1362 - acc: 0.9546 - val_loss: 0.8042 - val_acc: 0.8299\n",
      "Epoch 161/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1369 - acc: 0.9545 - val_loss: 0.8800 - val_acc: 0.8227\n",
      "Epoch 162/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1298 - acc: 0.9573 - val_loss: 0.8290 - val_acc: 0.8346\n",
      "Epoch 163/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1313 - acc: 0.9563 - val_loss: 0.8497 - val_acc: 0.8216\n",
      "Epoch 164/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.1296 - acc: 0.9568 - val_loss: 0.7381 - val_acc: 0.8314\n",
      "Epoch 165/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1293 - acc: 0.9571 - val_loss: 0.8270 - val_acc: 0.8306\n",
      "Epoch 166/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1237 - acc: 0.9589 - val_loss: 0.8582 - val_acc: 0.8241\n",
      "Epoch 167/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1314 - acc: 0.9574INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 31ms/step - loss: 0.1314 - acc: 0.9574 - val_loss: 0.7606 - val_acc: 0.8362\n",
      "Epoch 168/2000\n",
      "625/625 [==============================] - 20s 29ms/step - loss: 0.1303 - acc: 0.9558 - val_loss: 0.8287 - val_acc: 0.8265\n",
      "Epoch 169/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1256 - acc: 0.9575 - val_loss: 0.8568 - val_acc: 0.8341\n",
      "Epoch 170/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.1268 - acc: 0.9565 - val_loss: 0.8371 - val_acc: 0.8308\n",
      "Epoch 171/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.1267 - acc: 0.9578 - val_loss: 0.8991 - val_acc: 0.8269\n",
      "Epoch 172/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1230 - acc: 0.9590 - val_loss: 0.8311 - val_acc: 0.8338\n",
      "Epoch 173/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1241 - acc: 0.9588 - val_loss: 0.9337 - val_acc: 0.8230\n",
      "Epoch 174/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1234 - acc: 0.9588 - val_loss: 0.9116 - val_acc: 0.8271\n",
      "Epoch 175/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1191 - acc: 0.9615 - val_loss: 0.8108 - val_acc: 0.8354\n",
      "Epoch 176/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.9587INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1221 - acc: 0.9587 - val_loss: 0.8448 - val_acc: 0.8373\n",
      "Epoch 177/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1224 - acc: 0.9591 - val_loss: 0.8138 - val_acc: 0.8352\n",
      "Epoch 178/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1239 - acc: 0.9591INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.1239 - acc: 0.9591 - val_loss: 0.8101 - val_acc: 0.8374\n",
      "Epoch 179/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1172 - acc: 0.9614 - val_loss: 0.8361 - val_acc: 0.8287\n",
      "Epoch 180/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1196 - acc: 0.9601 - val_loss: 0.8415 - val_acc: 0.8329\n",
      "Epoch 181/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1169 - acc: 0.9612 - val_loss: 0.8816 - val_acc: 0.8321\n",
      "Epoch 182/2000\n",
      "625/625 [==============================] - 21s 30ms/step - loss: 0.1183 - acc: 0.9609 - val_loss: 0.8719 - val_acc: 0.8334\n",
      "Epoch 183/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1169 - acc: 0.9603 - val_loss: 0.7924 - val_acc: 0.8302\n",
      "Epoch 184/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9619INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 32ms/step - loss: 0.1156 - acc: 0.9619 - val_loss: 0.8393 - val_acc: 0.8375\n",
      "Epoch 185/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9626INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1140 - acc: 0.9626 - val_loss: 0.7994 - val_acc: 0.8395\n",
      "Epoch 186/2000\n",
      "625/625 [==============================] - 17s 24ms/step - loss: 0.1158 - acc: 0.9609 - val_loss: 0.9715 - val_acc: 0.8244\n",
      "Epoch 187/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1142 - acc: 0.9607 - val_loss: 0.8745 - val_acc: 0.8351\n",
      "Epoch 188/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1112 - acc: 0.9634 - val_loss: 0.9552 - val_acc: 0.8279\n",
      "Epoch 189/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1160 - acc: 0.9614 - val_loss: 0.7798 - val_acc: 0.8389\n",
      "Epoch 190/2000\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.1158 - acc: 0.9619 - val_loss: 0.8549 - val_acc: 0.8352\n",
      "Epoch 191/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1148 - acc: 0.9618INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 15s 20ms/step - loss: 0.1148 - acc: 0.9618 - val_loss: 0.8383 - val_acc: 0.8401\n",
      "Epoch 192/2000\n",
      "625/625 [==============================] - 18s 25ms/step - loss: 0.1118 - acc: 0.9635 - val_loss: 0.8060 - val_acc: 0.8338\n",
      "Epoch 193/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1094 - acc: 0.9641 - val_loss: 0.8095 - val_acc: 0.8390\n",
      "Epoch 194/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1147 - acc: 0.9623 - val_loss: 0.8368 - val_acc: 0.8381\n",
      "Epoch 195/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1150 - acc: 0.9618 - val_loss: 0.8234 - val_acc: 0.8342\n",
      "Epoch 196/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1111 - acc: 0.9630 - val_loss: 0.8781 - val_acc: 0.8383\n",
      "Epoch 197/2000\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9637INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1101 - acc: 0.9637 - val_loss: 0.8486 - val_acc: 0.8438\n",
      "Epoch 198/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1058 - acc: 0.9644 - val_loss: 0.8866 - val_acc: 0.8382\n",
      "Epoch 199/2000\n",
      "625/625 [==============================] - 21s 30ms/step - loss: 0.1108 - acc: 0.9631 - val_loss: 0.8410 - val_acc: 0.8373\n",
      "Epoch 200/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1084 - acc: 0.9640 - val_loss: 0.7960 - val_acc: 0.8395\n",
      "Epoch 201/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.1094 - acc: 0.9645 - val_loss: 0.8255 - val_acc: 0.8343\n",
      "Epoch 202/2000\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.1058 - acc: 0.9655 - val_loss: 0.8686 - val_acc: 0.8355\n",
      "Epoch 203/2000\n",
      "625/625 [==============================] - 15s 19ms/step - loss: 0.1083 - acc: 0.9642 - val_loss: 0.7971 - val_acc: 0.8410\n",
      "Epoch 204/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.1097 - acc: 0.9634 - val_loss: 0.8355 - val_acc: 0.8363\n",
      "Epoch 205/2000\n",
      "625/625 [==============================] - 18s 25ms/step - loss: 0.1065 - acc: 0.9649 - val_loss: 0.7977 - val_acc: 0.8364\n",
      "Epoch 206/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1032 - acc: 0.9659 - val_loss: 0.8543 - val_acc: 0.8374\n",
      "Epoch 207/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1098 - acc: 0.9632 - val_loss: 0.7910 - val_acc: 0.8425\n",
      "Epoch 208/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1045 - acc: 0.9644 - val_loss: 0.8222 - val_acc: 0.8416\n",
      "Epoch 209/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1038 - acc: 0.9645 - val_loss: 0.8196 - val_acc: 0.8352\n",
      "Epoch 210/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1068 - acc: 0.9651 - val_loss: 0.8495 - val_acc: 0.8349\n",
      "Epoch 211/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1055 - acc: 0.9646 - val_loss: 0.8502 - val_acc: 0.8367\n",
      "Epoch 212/2000\n",
      "625/625 [==============================] - 17s 23ms/step - loss: 0.1042 - acc: 0.9657 - val_loss: 0.7695 - val_acc: 0.8407\n",
      "Epoch 213/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.1010 - acc: 0.9668 - val_loss: 0.9099 - val_acc: 0.8370\n",
      "Epoch 214/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.1055 - acc: 0.9647 - val_loss: 0.8139 - val_acc: 0.8393\n",
      "Epoch 215/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1015 - acc: 0.9666 - val_loss: 0.8352 - val_acc: 0.8428\n",
      "Epoch 216/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0993 - acc: 0.9669 - val_loss: 0.8404 - val_acc: 0.8382\n",
      "Epoch 217/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1040 - acc: 0.9645 - val_loss: 0.8381 - val_acc: 0.8375\n",
      "Epoch 218/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.0984 - acc: 0.9678 - val_loss: 0.8440 - val_acc: 0.8340\n",
      "Epoch 219/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1005 - acc: 0.9669 - val_loss: 0.8436 - val_acc: 0.8407\n",
      "Epoch 220/2000\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.1026 - acc: 0.9657 - val_loss: 0.8071 - val_acc: 0.8415\n",
      "Epoch 221/2000\n",
      "625/625 [==============================] - 21s 30ms/step - loss: 0.1007 - acc: 0.9659 - val_loss: 0.9299 - val_acc: 0.8345\n",
      "Epoch 222/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9664INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 33ms/step - loss: 0.1010 - acc: 0.9664 - val_loss: 0.8314 - val_acc: 0.8450\n",
      "Epoch 223/2000\n",
      "625/625 [==============================] - 22s 29ms/step - loss: 0.0985 - acc: 0.9673 - val_loss: 0.7956 - val_acc: 0.8358\n",
      "Epoch 224/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0985 - acc: 0.9666INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.0985 - acc: 0.9666 - val_loss: 0.7873 - val_acc: 0.8472\n",
      "Epoch 225/2000\n",
      "625/625 [==============================] - 15s 20ms/step - loss: 0.0996 - acc: 0.9675 - val_loss: 0.8443 - val_acc: 0.8374\n",
      "Epoch 226/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.1017 - acc: 0.9663 - val_loss: 0.7564 - val_acc: 0.8449\n",
      "Epoch 227/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0967 - acc: 0.9684 - val_loss: 0.8270 - val_acc: 0.8405\n",
      "Epoch 228/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.1005 - acc: 0.9668 - val_loss: 0.7909 - val_acc: 0.8448\n",
      "Epoch 229/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.0956 - acc: 0.9682 - val_loss: 0.9048 - val_acc: 0.8384\n",
      "Epoch 230/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.0990 - acc: 0.9675 - val_loss: 0.8303 - val_acc: 0.8417\n",
      "Epoch 231/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.0904 - acc: 0.9693 - val_loss: 0.8332 - val_acc: 0.8380\n",
      "Epoch 232/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0975 - acc: 0.9677 - val_loss: 0.8053 - val_acc: 0.8433\n",
      "Epoch 233/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.1000 - acc: 0.9672 - val_loss: 0.8758 - val_acc: 0.8377\n",
      "Epoch 234/2000\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.0927 - acc: 0.9698 - val_loss: 0.8240 - val_acc: 0.8436\n",
      "Epoch 235/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0957 - acc: 0.9692 - val_loss: 0.7749 - val_acc: 0.8454\n",
      "Epoch 236/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0931 - acc: 0.9689 - val_loss: 0.8087 - val_acc: 0.8459\n",
      "Epoch 237/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.0947 - acc: 0.9676 - val_loss: 0.8707 - val_acc: 0.8446\n",
      "Epoch 238/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.0964 - acc: 0.9686 - val_loss: 0.8189 - val_acc: 0.8425\n",
      "Epoch 239/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0918 - acc: 0.9698 - val_loss: 0.8553 - val_acc: 0.8444\n",
      "Epoch 240/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0930 - acc: 0.9683INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 24s 33ms/step - loss: 0.0930 - acc: 0.9683 - val_loss: 0.8240 - val_acc: 0.8495\n",
      "Epoch 241/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0937 - acc: 0.9684 - val_loss: 0.8329 - val_acc: 0.8467\n",
      "Epoch 242/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0976 - acc: 0.9681 - val_loss: 0.8831 - val_acc: 0.8375\n",
      "Epoch 243/2000\n",
      "625/625 [==============================] - 17s 22ms/step - loss: 0.0922 - acc: 0.9699 - val_loss: 0.8890 - val_acc: 0.8396\n",
      "Epoch 244/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0905 - acc: 0.9693 - val_loss: 0.8667 - val_acc: 0.8389\n",
      "Epoch 245/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0913 - acc: 0.9695 - val_loss: 0.7606 - val_acc: 0.8493\n",
      "Epoch 246/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0910 - acc: 0.9689 - val_loss: 0.8414 - val_acc: 0.8432\n",
      "Epoch 247/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.0940 - acc: 0.9681 - val_loss: 0.8616 - val_acc: 0.8382\n",
      "Epoch 248/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.0867 - acc: 0.9715 - val_loss: 0.9077 - val_acc: 0.8415\n",
      "Epoch 249/2000\n",
      "625/625 [==============================] - 18s 25ms/step - loss: 0.0906 - acc: 0.9697 - val_loss: 0.7638 - val_acc: 0.8452\n",
      "Epoch 250/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.0865 - acc: 0.9711 - val_loss: 0.8657 - val_acc: 0.8478\n",
      "Epoch 251/2000\n",
      "625/625 [==============================] - 20s 28ms/step - loss: 0.0926 - acc: 0.9700 - val_loss: 0.8073 - val_acc: 0.8413\n",
      "Epoch 252/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.0888 - acc: 0.9707 - val_loss: 0.8345 - val_acc: 0.8439\n",
      "Epoch 253/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9694INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.0936 - acc: 0.9694 - val_loss: 0.7601 - val_acc: 0.8498\n",
      "Epoch 254/2000\n",
      "625/625 [==============================] - 15s 21ms/step - loss: 0.0903 - acc: 0.9700 - val_loss: 0.8993 - val_acc: 0.8403\n",
      "Epoch 255/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.0877 - acc: 0.9710 - val_loss: 0.8539 - val_acc: 0.8481\n",
      "Epoch 256/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0872 - acc: 0.9699 - val_loss: 0.8542 - val_acc: 0.8420\n",
      "Epoch 257/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0851 - acc: 0.9723 - val_loss: 0.8652 - val_acc: 0.8418\n",
      "Epoch 258/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0899 - acc: 0.9704 - val_loss: 0.8918 - val_acc: 0.8427\n",
      "Epoch 259/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0901 - acc: 0.9704 - val_loss: 0.7676 - val_acc: 0.8495\n",
      "Epoch 260/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0867 - acc: 0.9703 - val_loss: 0.8696 - val_acc: 0.8447\n",
      "Epoch 261/2000\n",
      "625/625 [==============================] - 17s 22ms/step - loss: 0.0857 - acc: 0.9723 - val_loss: 0.8174 - val_acc: 0.8442\n",
      "Epoch 262/2000\n",
      "625/625 [==============================] - 19s 25ms/step - loss: 0.0869 - acc: 0.9716 - val_loss: 0.8536 - val_acc: 0.8441\n",
      "Epoch 263/2000\n",
      "625/625 [==============================] - 21s 29ms/step - loss: 0.0873 - acc: 0.9708 - val_loss: 0.8534 - val_acc: 0.8448\n",
      "Epoch 264/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0858 - acc: 0.9717 - val_loss: 0.7982 - val_acc: 0.8477\n",
      "Epoch 265/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0838 - acc: 0.9721 - val_loss: 1.0405 - val_acc: 0.8357\n",
      "Epoch 266/2000\n",
      "625/625 [==============================] - 16s 22ms/step - loss: 0.0873 - acc: 0.9713 - val_loss: 0.8494 - val_acc: 0.8479\n",
      "Epoch 267/2000\n",
      "625/625 [==============================] - 20s 29ms/step - loss: 0.0823 - acc: 0.9721 - val_loss: 0.8668 - val_acc: 0.8482\n",
      "Epoch 268/2000\n",
      "625/625 [==============================] - 16s 20ms/step - loss: 0.0851 - acc: 0.9712 - val_loss: 0.8478 - val_acc: 0.8491\n",
      "Epoch 269/2000\n",
      "625/625 [==============================] - 20s 27ms/step - loss: 0.0862 - acc: 0.9715 - val_loss: 0.8615 - val_acc: 0.8452\n",
      "Epoch 270/2000\n",
      "625/625 [==============================] - 22s 30ms/step - loss: 0.0823 - acc: 0.9716 - val_loss: 0.8951 - val_acc: 0.8439\n",
      "Epoch 271/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0861 - acc: 0.9714 - val_loss: 0.9447 - val_acc: 0.8428\n",
      "Epoch 272/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9733INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 25s 34ms/step - loss: 0.0850 - acc: 0.9733 - val_loss: 0.8162 - val_acc: 0.8510\n",
      "Epoch 273/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0778 - acc: 0.9742 - val_loss: 0.9150 - val_acc: 0.8470\n",
      "Epoch 274/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9709INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 18s 25ms/step - loss: 0.0865 - acc: 0.9709 - val_loss: 0.8397 - val_acc: 0.8520\n",
      "Epoch 275/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.0824 - acc: 0.9734 - val_loss: 0.8877 - val_acc: 0.8489\n",
      "Epoch 276/2000\n",
      "625/625 [==============================] - 21s 28ms/step - loss: 0.0820 - acc: 0.9725 - val_loss: 0.8228 - val_acc: 0.8488\n",
      "Epoch 277/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9728INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 23s 31ms/step - loss: 0.0838 - acc: 0.9728 - val_loss: 0.8158 - val_acc: 0.8539\n",
      "Epoch 278/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0831 - acc: 0.9727INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 22s 31ms/step - loss: 0.0831 - acc: 0.9727 - val_loss: 0.8069 - val_acc: 0.8543\n",
      "Epoch 279/2000\n",
      "625/625 [==============================] - 16s 21ms/step - loss: 0.0826 - acc: 0.9725 - val_loss: 0.8113 - val_acc: 0.8520\n",
      "Epoch 280/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0827 - acc: 0.9734 - val_loss: 0.8271 - val_acc: 0.8516\n",
      "Epoch 281/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0836 - acc: 0.9724 - val_loss: 0.7828 - val_acc: 0.8453\n",
      "Epoch 282/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0783 - acc: 0.9742 - val_loss: 0.8829 - val_acc: 0.8426\n",
      "Epoch 283/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0848 - acc: 0.9731 - val_loss: 0.8092 - val_acc: 0.8423\n",
      "Epoch 284/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0808 - acc: 0.9732 - val_loss: 0.8165 - val_acc: 0.8480\n",
      "Epoch 285/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0825 - acc: 0.9728 - val_loss: 0.9411 - val_acc: 0.8405\n",
      "Epoch 286/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0751 - acc: 0.9742 - val_loss: 0.9120 - val_acc: 0.8467\n",
      "Epoch 287/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0775 - acc: 0.9746 - val_loss: 0.8340 - val_acc: 0.8470\n",
      "Epoch 288/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0837 - acc: 0.9730 - val_loss: 0.8357 - val_acc: 0.8443\n",
      "Epoch 289/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0823 - acc: 0.9727 - val_loss: 1.0012 - val_acc: 0.8379\n",
      "Epoch 290/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0792 - acc: 0.9734 - val_loss: 0.9388 - val_acc: 0.8446\n",
      "Epoch 291/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0810 - acc: 0.9734 - val_loss: 0.9000 - val_acc: 0.8408\n",
      "Epoch 292/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0777 - acc: 0.9746 - val_loss: 0.8453 - val_acc: 0.8479\n",
      "Epoch 293/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0835 - acc: 0.9729 - val_loss: 0.8481 - val_acc: 0.8506\n",
      "Epoch 294/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0790 - acc: 0.9754 - val_loss: 0.8397 - val_acc: 0.8477\n",
      "Epoch 295/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0784 - acc: 0.9741 - val_loss: 0.8739 - val_acc: 0.8417\n",
      "Epoch 296/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0768 - acc: 0.9749 - val_loss: 0.8603 - val_acc: 0.8475\n",
      "Epoch 297/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.9754INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0756 - acc: 0.9754 - val_loss: 0.7692 - val_acc: 0.8559\n",
      "Epoch 298/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0782 - acc: 0.9738 - val_loss: 0.8782 - val_acc: 0.8460\n",
      "Epoch 299/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0795 - acc: 0.9740 - val_loss: 0.9137 - val_acc: 0.8449\n",
      "Epoch 300/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0768 - acc: 0.9752 - val_loss: 0.7698 - val_acc: 0.8509\n",
      "Epoch 301/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0764 - acc: 0.9747 - val_loss: 0.8544 - val_acc: 0.8447\n",
      "Epoch 302/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0791 - acc: 0.9740 - val_loss: 0.9593 - val_acc: 0.8403\n",
      "Epoch 303/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0769 - acc: 0.9752 - val_loss: 0.8856 - val_acc: 0.8429\n",
      "Epoch 304/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0757 - acc: 0.9748 - val_loss: 0.9747 - val_acc: 0.8370\n",
      "Epoch 305/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0763 - acc: 0.9753 - val_loss: 0.9573 - val_acc: 0.8423\n",
      "Epoch 306/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0766 - acc: 0.9746 - val_loss: 0.9905 - val_acc: 0.8448\n",
      "Epoch 307/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0779 - acc: 0.9748 - val_loss: 0.8838 - val_acc: 0.8510\n",
      "Epoch 308/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0778 - acc: 0.9746 - val_loss: 0.8955 - val_acc: 0.8475\n",
      "Epoch 309/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0731 - acc: 0.9759 - val_loss: 0.8872 - val_acc: 0.8500\n",
      "Epoch 310/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0753 - acc: 0.9750 - val_loss: 0.8203 - val_acc: 0.8484\n",
      "Epoch 311/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0754 - acc: 0.9754 - val_loss: 0.8103 - val_acc: 0.8471\n",
      "Epoch 312/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0718 - acc: 0.9765 - val_loss: 0.9065 - val_acc: 0.8511\n",
      "Epoch 313/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0746 - acc: 0.9756 - val_loss: 0.7969 - val_acc: 0.8535\n",
      "Epoch 314/2000\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9746INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0758 - acc: 0.9746 - val_loss: 0.7744 - val_acc: 0.8581\n",
      "Epoch 315/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0772 - acc: 0.9754 - val_loss: 0.7929 - val_acc: 0.8540\n",
      "Epoch 316/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0767 - acc: 0.9743 - val_loss: 0.8539 - val_acc: 0.8448\n",
      "Epoch 317/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0749 - acc: 0.9753 - val_loss: 0.8890 - val_acc: 0.8542\n",
      "Epoch 318/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0722 - acc: 0.9767 - val_loss: 0.9277 - val_acc: 0.8474\n",
      "Epoch 319/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0763 - acc: 0.9758 - val_loss: 0.8722 - val_acc: 0.8518\n",
      "Epoch 320/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0731 - acc: 0.9759 - val_loss: 0.8937 - val_acc: 0.8515\n",
      "Epoch 321/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0724 - acc: 0.9759 - val_loss: 0.8849 - val_acc: 0.8479\n",
      "Epoch 322/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0708 - acc: 0.9769 - val_loss: 0.9512 - val_acc: 0.8414\n",
      "Epoch 323/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0722 - acc: 0.9760 - val_loss: 0.9401 - val_acc: 0.8463\n",
      "Epoch 324/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0763 - acc: 0.9754 - val_loss: 0.8341 - val_acc: 0.8475\n",
      "Epoch 325/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0753 - acc: 0.9760 - val_loss: 0.7677 - val_acc: 0.8495\n",
      "Epoch 326/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0718 - acc: 0.9766 - val_loss: 0.8731 - val_acc: 0.8467\n",
      "Epoch 327/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0686 - acc: 0.9776 - val_loss: 0.9604 - val_acc: 0.8451\n",
      "Epoch 328/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0722 - acc: 0.9767 - val_loss: 0.8475 - val_acc: 0.8505\n",
      "Epoch 329/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0691 - acc: 0.9776 - val_loss: 0.8827 - val_acc: 0.8487\n",
      "Epoch 330/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0732 - acc: 0.9753 - val_loss: 0.8517 - val_acc: 0.8458\n",
      "Epoch 331/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0719 - acc: 0.9763 - val_loss: 0.9145 - val_acc: 0.8421\n",
      "Epoch 332/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0717 - acc: 0.9763 - val_loss: 0.8991 - val_acc: 0.8455\n",
      "Epoch 333/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0698 - acc: 0.9767 - val_loss: 0.8407 - val_acc: 0.8533\n",
      "Epoch 334/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0732 - acc: 0.9758 - val_loss: 0.8497 - val_acc: 0.8471\n",
      "Epoch 335/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0693 - acc: 0.9773 - val_loss: 0.8774 - val_acc: 0.8530\n",
      "Epoch 336/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0707 - acc: 0.9762 - val_loss: 0.9555 - val_acc: 0.8428\n",
      "Epoch 337/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0717 - acc: 0.9763 - val_loss: 0.9025 - val_acc: 0.8464\n",
      "Epoch 338/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0732 - acc: 0.9751 - val_loss: 0.8467 - val_acc: 0.8466\n",
      "Epoch 339/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0703 - acc: 0.9772 - val_loss: 0.9317 - val_acc: 0.8459\n",
      "Epoch 340/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0685 - acc: 0.9768 - val_loss: 0.8829 - val_acc: 0.8509\n",
      "Epoch 341/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0667 - acc: 0.9774 - val_loss: 0.8358 - val_acc: 0.8535\n",
      "Epoch 342/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0687 - acc: 0.9774 - val_loss: 0.8628 - val_acc: 0.8466\n",
      "Epoch 343/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0675 - acc: 0.9769 - val_loss: 0.7898 - val_acc: 0.8477\n",
      "Epoch 344/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0707 - acc: 0.9764 - val_loss: 0.9626 - val_acc: 0.8408\n",
      "Epoch 345/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0669 - acc: 0.9779 - val_loss: 0.8966 - val_acc: 0.8456\n",
      "Epoch 346/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0672 - acc: 0.9783 - val_loss: 0.9065 - val_acc: 0.8505\n",
      "Epoch 347/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0684 - acc: 0.9770 - val_loss: 0.8553 - val_acc: 0.8493\n",
      "Epoch 348/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0677 - acc: 0.9783 - val_loss: 0.8980 - val_acc: 0.8525\n",
      "Epoch 349/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0668 - acc: 0.9777 - val_loss: 0.8408 - val_acc: 0.8526\n",
      "Epoch 350/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0696 - acc: 0.9773 - val_loss: 0.8735 - val_acc: 0.8490\n",
      "Epoch 351/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0664 - acc: 0.9785 - val_loss: 0.8667 - val_acc: 0.8504\n",
      "Epoch 352/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0701 - acc: 0.9778 - val_loss: 0.8956 - val_acc: 0.8539\n",
      "Epoch 353/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0680 - acc: 0.9784 - val_loss: 0.8308 - val_acc: 0.8516\n",
      "Epoch 354/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0695 - acc: 0.9774 - val_loss: 0.8577 - val_acc: 0.8475\n",
      "Epoch 355/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0688 - acc: 0.9780 - val_loss: 0.8544 - val_acc: 0.8493\n",
      "Epoch 356/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0700 - acc: 0.9775 - val_loss: 0.8799 - val_acc: 0.8521\n",
      "Epoch 357/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0709 - acc: 0.9763 - val_loss: 0.8587 - val_acc: 0.8523\n",
      "Epoch 358/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0663 - acc: 0.9780 - val_loss: 0.8848 - val_acc: 0.8535\n",
      "Epoch 359/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0668 - acc: 0.9784 - val_loss: 0.8871 - val_acc: 0.8521\n",
      "Epoch 360/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0649 - acc: 0.9784 - val_loss: 0.8752 - val_acc: 0.8513\n",
      "Epoch 361/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0644 - acc: 0.9782 - val_loss: 0.9252 - val_acc: 0.8509\n",
      "Epoch 362/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0652 - acc: 0.9785 - val_loss: 0.9188 - val_acc: 0.8499\n",
      "Epoch 363/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0640 - acc: 0.9788 - val_loss: 0.9051 - val_acc: 0.8493\n",
      "Epoch 364/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0673 - acc: 0.9786 - val_loss: 0.8297 - val_acc: 0.8534\n",
      "Epoch 365/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0661 - acc: 0.9782 - val_loss: 0.8765 - val_acc: 0.8554\n",
      "Epoch 366/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0660 - acc: 0.9783 - val_loss: 0.8311 - val_acc: 0.8500\n",
      "Epoch 367/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0640 - acc: 0.9789 - val_loss: 0.9963 - val_acc: 0.8445\n",
      "Epoch 368/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0631 - acc: 0.9785 - val_loss: 0.9369 - val_acc: 0.8520\n",
      "Epoch 369/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0620 - acc: 0.9792 - val_loss: 0.8736 - val_acc: 0.8505\n",
      "Epoch 370/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0652 - acc: 0.9784 - val_loss: 0.8738 - val_acc: 0.8441\n",
      "Epoch 371/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0663 - acc: 0.9779 - val_loss: 0.8586 - val_acc: 0.8476\n",
      "Epoch 372/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0643 - acc: 0.9788 - val_loss: 0.9126 - val_acc: 0.8449\n",
      "Epoch 373/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0672 - acc: 0.9779 - val_loss: 0.9512 - val_acc: 0.8460\n",
      "Epoch 374/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0647 - acc: 0.9785 - val_loss: 0.8970 - val_acc: 0.8489\n",
      "Epoch 375/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0705 - acc: 0.9769 - val_loss: 0.9275 - val_acc: 0.8489\n",
      "Epoch 376/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0656 - acc: 0.9780 - val_loss: 0.8892 - val_acc: 0.8492\n",
      "Epoch 377/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0647 - acc: 0.9789 - val_loss: 0.7671 - val_acc: 0.8551\n",
      "Epoch 378/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0628 - acc: 0.9797 - val_loss: 0.8059 - val_acc: 0.8530\n",
      "Epoch 379/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0627 - acc: 0.9796 - val_loss: 0.9051 - val_acc: 0.8501\n",
      "Epoch 380/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0616 - acc: 0.9796 - val_loss: 0.9159 - val_acc: 0.8568\n",
      "Epoch 381/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0653 - acc: 0.9785 - val_loss: 0.9015 - val_acc: 0.8476\n",
      "Epoch 382/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0658 - acc: 0.9788 - val_loss: 0.8715 - val_acc: 0.8469\n",
      "Epoch 383/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0621 - acc: 0.9794 - val_loss: 0.8795 - val_acc: 0.8509\n",
      "Epoch 384/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0661 - acc: 0.9789 - val_loss: 0.8342 - val_acc: 0.8555\n",
      "Epoch 385/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0623 - acc: 0.9795 - val_loss: 0.9064 - val_acc: 0.8532\n",
      "Epoch 386/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0628 - acc: 0.9797 - val_loss: 0.9598 - val_acc: 0.8533\n",
      "Epoch 387/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0638 - acc: 0.9792 - val_loss: 0.8784 - val_acc: 0.8477\n",
      "Epoch 388/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0617 - acc: 0.9803 - val_loss: 0.8560 - val_acc: 0.8471\n",
      "Epoch 389/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0627 - acc: 0.9802 - val_loss: 0.8656 - val_acc: 0.8510\n",
      "Epoch 390/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0633 - acc: 0.9788 - val_loss: 0.9362 - val_acc: 0.8466\n",
      "Epoch 391/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0617 - acc: 0.9804 - val_loss: 0.9493 - val_acc: 0.8498\n",
      "Epoch 392/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0616 - acc: 0.9801 - val_loss: 0.9521 - val_acc: 0.8475\n",
      "Epoch 393/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0632 - acc: 0.9788 - val_loss: 0.8483 - val_acc: 0.8493\n",
      "Epoch 394/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0630 - acc: 0.9797 - val_loss: 0.9045 - val_acc: 0.8500\n",
      "Epoch 395/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0653 - acc: 0.9791 - val_loss: 0.8756 - val_acc: 0.8510\n",
      "Epoch 396/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0598 - acc: 0.9800 - val_loss: 0.9236 - val_acc: 0.8545\n",
      "Epoch 397/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0615 - acc: 0.9796INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.0615 - acc: 0.9796 - val_loss: 0.8554 - val_acc: 0.8582\n",
      "Epoch 398/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0619 - acc: 0.9794INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0619 - acc: 0.9794 - val_loss: 0.8779 - val_acc: 0.8591\n",
      "Epoch 399/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0648 - acc: 0.9793 - val_loss: 0.8924 - val_acc: 0.8514\n",
      "Epoch 400/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0632 - acc: 0.9797 - val_loss: 0.8598 - val_acc: 0.8471\n",
      "Epoch 401/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0605 - acc: 0.9801 - val_loss: 0.9967 - val_acc: 0.8473\n",
      "Epoch 402/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0624 - acc: 0.9794 - val_loss: 0.9991 - val_acc: 0.8467\n",
      "Epoch 403/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0637 - acc: 0.9787 - val_loss: 0.9378 - val_acc: 0.8453\n",
      "Epoch 404/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0615 - acc: 0.9797 - val_loss: 0.8819 - val_acc: 0.8538\n",
      "Epoch 405/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0605 - acc: 0.9795 - val_loss: 0.8523 - val_acc: 0.8549\n",
      "Epoch 406/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0606 - acc: 0.9808 - val_loss: 0.8807 - val_acc: 0.8511\n",
      "Epoch 407/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0604 - acc: 0.9794 - val_loss: 0.9589 - val_acc: 0.8551\n",
      "Epoch 408/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0608 - acc: 0.9801 - val_loss: 0.9431 - val_acc: 0.8527\n",
      "Epoch 409/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0597 - acc: 0.9809 - val_loss: 0.9101 - val_acc: 0.8563\n",
      "Epoch 410/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0623 - acc: 0.9794 - val_loss: 0.8320 - val_acc: 0.8562\n",
      "Epoch 411/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0583 - acc: 0.9807 - val_loss: 0.9448 - val_acc: 0.8511\n",
      "Epoch 412/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0634 - acc: 0.9794 - val_loss: 0.8581 - val_acc: 0.8513\n",
      "Epoch 413/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0608 - acc: 0.9794 - val_loss: 0.8687 - val_acc: 0.8537\n",
      "Epoch 414/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0604 - acc: 0.9816 - val_loss: 0.8936 - val_acc: 0.8525\n",
      "Epoch 415/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0603 - acc: 0.9794 - val_loss: 0.8575 - val_acc: 0.8556\n",
      "Epoch 416/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0587 - acc: 0.9810 - val_loss: 0.8635 - val_acc: 0.8558\n",
      "Epoch 417/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0591 - acc: 0.9808 - val_loss: 0.9089 - val_acc: 0.8484\n",
      "Epoch 418/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0612 - acc: 0.9800 - val_loss: 0.8652 - val_acc: 0.8572\n",
      "Epoch 419/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0614 - acc: 0.9804 - val_loss: 0.8773 - val_acc: 0.8573\n",
      "Epoch 420/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0626 - acc: 0.9800 - val_loss: 0.8939 - val_acc: 0.8570\n",
      "Epoch 421/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0566 - acc: 0.9817 - val_loss: 1.0799 - val_acc: 0.8429\n",
      "Epoch 422/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0624 - acc: 0.9801 - val_loss: 0.8684 - val_acc: 0.8589\n",
      "Epoch 423/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.9809INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0604 - acc: 0.9809 - val_loss: 0.8619 - val_acc: 0.8609\n",
      "Epoch 424/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0610 - acc: 0.9798 - val_loss: 0.8643 - val_acc: 0.8505\n",
      "Epoch 425/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0553 - acc: 0.9821 - val_loss: 0.8593 - val_acc: 0.8536\n",
      "Epoch 426/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0657 - acc: 0.9783 - val_loss: 0.9655 - val_acc: 0.8433\n",
      "Epoch 427/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0571 - acc: 0.9812 - val_loss: 0.8260 - val_acc: 0.8526\n",
      "Epoch 428/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0581 - acc: 0.9804 - val_loss: 0.8905 - val_acc: 0.8555\n",
      "Epoch 429/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0598 - acc: 0.9795 - val_loss: 0.8688 - val_acc: 0.8536\n",
      "Epoch 430/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0595 - acc: 0.9808 - val_loss: 0.8828 - val_acc: 0.8567\n",
      "Epoch 431/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0593 - acc: 0.9805 - val_loss: 0.9126 - val_acc: 0.8533\n",
      "Epoch 432/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0587 - acc: 0.9805 - val_loss: 0.9261 - val_acc: 0.8559\n",
      "Epoch 433/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0615 - acc: 0.9800 - val_loss: 0.8731 - val_acc: 0.8475\n",
      "Epoch 434/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0560 - acc: 0.9818 - val_loss: 0.8320 - val_acc: 0.8535\n",
      "Epoch 435/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0596 - acc: 0.9803 - val_loss: 0.9143 - val_acc: 0.8492\n",
      "Epoch 436/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0592 - acc: 0.9812 - val_loss: 0.9103 - val_acc: 0.8567\n",
      "Epoch 437/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0547 - acc: 0.9819 - val_loss: 0.9292 - val_acc: 0.8541\n",
      "Epoch 438/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0544 - acc: 0.9815 - val_loss: 0.9605 - val_acc: 0.8568\n",
      "Epoch 439/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0574 - acc: 0.9816 - val_loss: 0.9585 - val_acc: 0.8579\n",
      "Epoch 440/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0575 - acc: 0.9814 - val_loss: 0.9072 - val_acc: 0.8555\n",
      "Epoch 441/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0598 - acc: 0.9808 - val_loss: 0.8539 - val_acc: 0.8523\n",
      "Epoch 442/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0557 - acc: 0.9814 - val_loss: 0.8621 - val_acc: 0.8596\n",
      "Epoch 443/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0555 - acc: 0.9815 - val_loss: 0.9186 - val_acc: 0.8517\n",
      "Epoch 444/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0550 - acc: 0.9825 - val_loss: 0.9474 - val_acc: 0.8527\n",
      "Epoch 445/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0583 - acc: 0.9806 - val_loss: 0.8945 - val_acc: 0.8585\n",
      "Epoch 446/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0544 - acc: 0.9825 - val_loss: 0.9759 - val_acc: 0.8553\n",
      "Epoch 447/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0583 - acc: 0.9802 - val_loss: 0.9007 - val_acc: 0.8543\n",
      "Epoch 448/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0583 - acc: 0.9808 - val_loss: 0.8662 - val_acc: 0.8538\n",
      "Epoch 449/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0594 - acc: 0.9812 - val_loss: 0.8793 - val_acc: 0.8597\n",
      "Epoch 450/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0550 - acc: 0.9817 - val_loss: 0.8818 - val_acc: 0.8575\n",
      "Epoch 451/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0599 - acc: 0.9809 - val_loss: 0.8307 - val_acc: 0.8584\n",
      "Epoch 452/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0553 - acc: 0.9828 - val_loss: 0.8260 - val_acc: 0.8538\n",
      "Epoch 453/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0571 - acc: 0.9816 - val_loss: 0.8864 - val_acc: 0.8581\n",
      "Epoch 454/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0545 - acc: 0.9825 - val_loss: 1.0130 - val_acc: 0.8566\n",
      "Epoch 455/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0567 - acc: 0.9808 - val_loss: 0.9896 - val_acc: 0.8529\n",
      "Epoch 456/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0569 - acc: 0.9821 - val_loss: 0.8439 - val_acc: 0.8557\n",
      "Epoch 457/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0555 - acc: 0.9818 - val_loss: 0.9921 - val_acc: 0.8562\n",
      "Epoch 458/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0551 - acc: 0.9818 - val_loss: 0.9080 - val_acc: 0.8548\n",
      "Epoch 459/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0538 - acc: 0.9826 - val_loss: 0.8768 - val_acc: 0.8590\n",
      "Epoch 460/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0555 - acc: 0.9820 - val_loss: 0.9378 - val_acc: 0.8554\n",
      "Epoch 461/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0556 - acc: 0.9816 - val_loss: 0.8594 - val_acc: 0.8563\n",
      "Epoch 462/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0520 - acc: 0.9829 - val_loss: 0.9715 - val_acc: 0.8550\n",
      "Epoch 463/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0527 - acc: 0.9826 - val_loss: 0.9723 - val_acc: 0.8567\n",
      "Epoch 464/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0552 - acc: 0.9817 - val_loss: 1.0378 - val_acc: 0.8443\n",
      "Epoch 465/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0580 - acc: 0.9818 - val_loss: 0.8816 - val_acc: 0.8582\n",
      "Epoch 466/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0532 - acc: 0.9825 - val_loss: 0.9570 - val_acc: 0.8567\n",
      "Epoch 467/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0558 - acc: 0.9823 - val_loss: 0.8685 - val_acc: 0.8584\n",
      "Epoch 468/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0562 - acc: 0.9819 - val_loss: 0.8995 - val_acc: 0.8608\n",
      "Epoch 469/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0535 - acc: 0.9817 - val_loss: 0.9132 - val_acc: 0.8552\n",
      "Epoch 470/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0536 - acc: 0.9825 - val_loss: 0.9745 - val_acc: 0.8515\n",
      "Epoch 471/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0546 - acc: 0.9827 - val_loss: 0.9313 - val_acc: 0.8513\n",
      "Epoch 472/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0510 - acc: 0.9830 - val_loss: 0.9140 - val_acc: 0.8548\n",
      "Epoch 473/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0539 - acc: 0.9823 - val_loss: 0.9574 - val_acc: 0.8531\n",
      "Epoch 474/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0557 - acc: 0.9821 - val_loss: 0.9329 - val_acc: 0.8550\n",
      "Epoch 475/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0515 - acc: 0.9834 - val_loss: 0.9392 - val_acc: 0.8599\n",
      "Epoch 476/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0597 - acc: 0.9811 - val_loss: 0.9436 - val_acc: 0.8487\n",
      "Epoch 477/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0572 - acc: 0.9816 - val_loss: 0.9241 - val_acc: 0.8511\n",
      "Epoch 478/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0536 - acc: 0.9823 - val_loss: 1.0318 - val_acc: 0.8498\n",
      "Epoch 479/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0517 - acc: 0.9832 - val_loss: 1.0084 - val_acc: 0.8498\n",
      "Epoch 480/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0560 - acc: 0.9818 - val_loss: 0.8783 - val_acc: 0.8534\n",
      "Epoch 481/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0550 - acc: 0.9819 - val_loss: 0.9063 - val_acc: 0.8499\n",
      "Epoch 482/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0538 - acc: 0.9832 - val_loss: 0.9090 - val_acc: 0.8529\n",
      "Epoch 483/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0547 - acc: 0.9820INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.0547 - acc: 0.9820 - val_loss: 0.8660 - val_acc: 0.8620\n",
      "Epoch 484/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0533 - acc: 0.9824 - val_loss: 0.8413 - val_acc: 0.8597\n",
      "Epoch 485/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0547 - acc: 0.9822 - val_loss: 0.9598 - val_acc: 0.8583\n",
      "Epoch 486/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0549 - acc: 0.9822 - val_loss: 0.8477 - val_acc: 0.8544\n",
      "Epoch 487/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0533 - acc: 0.9827 - val_loss: 1.0274 - val_acc: 0.8619\n",
      "Epoch 488/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0530 - acc: 0.9822INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 15s 20ms/step - loss: 0.0530 - acc: 0.9822 - val_loss: 0.9521 - val_acc: 0.8625\n",
      "Epoch 489/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0522 - acc: 0.9824 - val_loss: 0.9911 - val_acc: 0.8582\n",
      "Epoch 490/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0543 - acc: 0.9823 - val_loss: 0.9239 - val_acc: 0.8588\n",
      "Epoch 491/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0515 - acc: 0.9830 - val_loss: 1.0033 - val_acc: 0.8603\n",
      "Epoch 492/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0524 - acc: 0.9827 - val_loss: 0.9816 - val_acc: 0.8486\n",
      "Epoch 493/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0534 - acc: 0.9825 - val_loss: 1.0235 - val_acc: 0.8592\n",
      "Epoch 494/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0552 - acc: 0.9821 - val_loss: 0.8259 - val_acc: 0.8580\n",
      "Epoch 495/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0481 - acc: 0.9837 - val_loss: 1.0326 - val_acc: 0.8550\n",
      "Epoch 496/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0511 - acc: 0.9833 - val_loss: 1.0047 - val_acc: 0.8620\n",
      "Epoch 497/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0529 - acc: 0.9833 - val_loss: 0.9742 - val_acc: 0.8562\n",
      "Epoch 498/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0534 - acc: 0.9825 - val_loss: 1.0015 - val_acc: 0.8470\n",
      "Epoch 499/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0527 - acc: 0.9825 - val_loss: 0.8957 - val_acc: 0.8549\n",
      "Epoch 500/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0546 - acc: 0.9822 - val_loss: 0.8742 - val_acc: 0.8567\n",
      "Epoch 501/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0502 - acc: 0.9837 - val_loss: 0.8960 - val_acc: 0.8577\n",
      "Epoch 502/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0526 - acc: 0.9824 - val_loss: 0.9816 - val_acc: 0.8593\n",
      "Epoch 503/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0525 - acc: 0.9827 - val_loss: 0.9915 - val_acc: 0.8599\n",
      "Epoch 504/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0518 - acc: 0.9829 - val_loss: 1.0177 - val_acc: 0.8489\n",
      "Epoch 505/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0555 - acc: 0.9818 - val_loss: 1.0727 - val_acc: 0.8585\n",
      "Epoch 506/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0497 - acc: 0.9839 - val_loss: 0.9096 - val_acc: 0.8586\n",
      "Epoch 507/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0518 - acc: 0.9837 - val_loss: 0.8955 - val_acc: 0.8561\n",
      "Epoch 508/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0487 - acc: 0.9836 - val_loss: 0.9479 - val_acc: 0.8548\n",
      "Epoch 509/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0516 - acc: 0.9828 - val_loss: 0.9607 - val_acc: 0.8569\n",
      "Epoch 510/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0527 - acc: 0.9829 - val_loss: 0.9520 - val_acc: 0.8601\n",
      "Epoch 511/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0516 - acc: 0.9828 - val_loss: 0.9514 - val_acc: 0.8515\n",
      "Epoch 512/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0491 - acc: 0.9846 - val_loss: 1.0505 - val_acc: 0.8558\n",
      "Epoch 513/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0492 - acc: 0.9847INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0492 - acc: 0.9847 - val_loss: 0.8862 - val_acc: 0.8629\n",
      "Epoch 514/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0507 - acc: 0.9837 - val_loss: 1.0053 - val_acc: 0.8603\n",
      "Epoch 515/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0540 - acc: 0.9815 - val_loss: 0.9024 - val_acc: 0.8553\n",
      "Epoch 516/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0512 - acc: 0.9831 - val_loss: 1.0028 - val_acc: 0.8512\n",
      "Epoch 517/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0530 - acc: 0.9829 - val_loss: 0.8917 - val_acc: 0.8546\n",
      "Epoch 518/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0483 - acc: 0.9845 - val_loss: 0.9955 - val_acc: 0.8586\n",
      "Epoch 519/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0510 - acc: 0.9837 - val_loss: 0.9574 - val_acc: 0.8562\n",
      "Epoch 520/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0489 - acc: 0.9844 - val_loss: 0.9207 - val_acc: 0.8576\n",
      "Epoch 521/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.9837INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0513 - acc: 0.9837 - val_loss: 0.9376 - val_acc: 0.8630\n",
      "Epoch 522/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.9656 - val_acc: 0.8516\n",
      "Epoch 523/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0524 - acc: 0.9822 - val_loss: 0.8652 - val_acc: 0.8575\n",
      "Epoch 524/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0510 - acc: 0.9838 - val_loss: 0.8196 - val_acc: 0.8589\n",
      "Epoch 525/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0497 - acc: 0.9836 - val_loss: 0.8732 - val_acc: 0.8564\n",
      "Epoch 526/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0480 - acc: 0.9839 - val_loss: 0.9437 - val_acc: 0.8557\n",
      "Epoch 527/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0494 - acc: 0.9837 - val_loss: 0.9094 - val_acc: 0.8578\n",
      "Epoch 528/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0498 - acc: 0.9836 - val_loss: 0.9269 - val_acc: 0.8614\n",
      "Epoch 529/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0525 - acc: 0.9836 - val_loss: 0.8955 - val_acc: 0.8566\n",
      "Epoch 530/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0526 - acc: 0.9826 - val_loss: 0.9353 - val_acc: 0.8564\n",
      "Epoch 531/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0530 - acc: 0.9834 - val_loss: 0.9016 - val_acc: 0.8591\n",
      "Epoch 532/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0475 - acc: 0.9842 - val_loss: 1.0336 - val_acc: 0.8528\n",
      "Epoch 533/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0478 - acc: 0.9843 - val_loss: 0.9841 - val_acc: 0.8545\n",
      "Epoch 534/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0476 - acc: 0.9845 - val_loss: 1.0291 - val_acc: 0.8570\n",
      "Epoch 535/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0526 - acc: 0.9834 - val_loss: 0.9220 - val_acc: 0.8503\n",
      "Epoch 536/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0480 - acc: 0.9842 - val_loss: 1.0252 - val_acc: 0.8532\n",
      "Epoch 537/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0513 - acc: 0.9832 - val_loss: 0.9959 - val_acc: 0.8595\n",
      "Epoch 538/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0480 - acc: 0.9843 - val_loss: 1.0540 - val_acc: 0.8626\n",
      "Epoch 539/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0482 - acc: 0.9843 - val_loss: 1.1404 - val_acc: 0.8547\n",
      "Epoch 540/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0475 - acc: 0.9840 - val_loss: 1.0634 - val_acc: 0.8557\n",
      "Epoch 541/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0533 - acc: 0.9833 - val_loss: 0.9735 - val_acc: 0.8551\n",
      "Epoch 542/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0484 - acc: 0.9837 - val_loss: 1.1373 - val_acc: 0.8470\n",
      "Epoch 543/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0499 - acc: 0.9839 - val_loss: 1.0194 - val_acc: 0.8555\n",
      "Epoch 544/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0516 - acc: 0.9832 - val_loss: 0.9936 - val_acc: 0.8577\n",
      "Epoch 545/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0498 - acc: 0.9837 - val_loss: 1.0099 - val_acc: 0.8581\n",
      "Epoch 546/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0527 - acc: 0.9834 - val_loss: 0.8810 - val_acc: 0.8580\n",
      "Epoch 547/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0502 - acc: 0.9839 - val_loss: 0.9460 - val_acc: 0.8587\n",
      "Epoch 548/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0484 - acc: 0.9843 - val_loss: 0.9640 - val_acc: 0.8585\n",
      "Epoch 549/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 0.9825 - val_acc: 0.8566\n",
      "Epoch 550/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0482 - acc: 0.9845 - val_loss: 1.1156 - val_acc: 0.8593\n",
      "Epoch 551/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0481 - acc: 0.9845 - val_loss: 0.9476 - val_acc: 0.8576\n",
      "Epoch 552/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0515 - acc: 0.9832 - val_loss: 0.9165 - val_acc: 0.8603\n",
      "Epoch 553/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0475 - acc: 0.9844 - val_loss: 0.9441 - val_acc: 0.8604\n",
      "Epoch 554/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0508 - acc: 0.9837 - val_loss: 1.0845 - val_acc: 0.8538\n",
      "Epoch 555/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0501 - acc: 0.9844 - val_loss: 0.9759 - val_acc: 0.8535\n",
      "Epoch 556/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0508 - acc: 0.9834 - val_loss: 0.9224 - val_acc: 0.8575\n",
      "Epoch 557/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0465 - acc: 0.9850 - val_loss: 0.9294 - val_acc: 0.8626\n",
      "Epoch 558/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0480 - acc: 0.9850 - val_loss: 0.9722 - val_acc: 0.8519\n",
      "Epoch 559/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0438 - acc: 0.9855 - val_loss: 0.9488 - val_acc: 0.8617\n",
      "Epoch 560/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0515 - acc: 0.9835 - val_loss: 0.8283 - val_acc: 0.8584\n",
      "Epoch 561/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0466 - acc: 0.9848 - val_loss: 0.9229 - val_acc: 0.8573\n",
      "Epoch 562/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0463 - acc: 0.9849 - val_loss: 0.9299 - val_acc: 0.8595\n",
      "Epoch 563/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0495 - acc: 0.9847 - val_loss: 0.9515 - val_acc: 0.8583\n",
      "Epoch 564/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0472 - acc: 0.9845 - val_loss: 1.0601 - val_acc: 0.8560\n",
      "Epoch 565/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0487 - acc: 0.9846 - val_loss: 1.0477 - val_acc: 0.8485\n",
      "Epoch 566/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0496 - acc: 0.9842 - val_loss: 0.9209 - val_acc: 0.8555\n",
      "Epoch 567/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0477 - acc: 0.9847 - val_loss: 0.8972 - val_acc: 0.8599\n",
      "Epoch 568/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0468 - acc: 0.9846 - val_loss: 0.9811 - val_acc: 0.8592\n",
      "Epoch 569/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0469 - acc: 0.9850 - val_loss: 1.0374 - val_acc: 0.8589\n",
      "Epoch 570/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0502 - acc: 0.9841 - val_loss: 0.9349 - val_acc: 0.8575\n",
      "Epoch 571/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.8598 - val_acc: 0.8584\n",
      "Epoch 572/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0509 - acc: 0.9833 - val_loss: 0.8544 - val_acc: 0.8583\n",
      "Epoch 573/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0473 - acc: 0.9843 - val_loss: 0.8419 - val_acc: 0.8593\n",
      "Epoch 574/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0465 - acc: 0.9851 - val_loss: 1.0639 - val_acc: 0.8565\n",
      "Epoch 575/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0458 - acc: 0.9851 - val_loss: 1.0736 - val_acc: 0.8601\n",
      "Epoch 576/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0501 - acc: 0.9837 - val_loss: 1.0093 - val_acc: 0.8609\n",
      "Epoch 577/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0457 - acc: 0.9846 - val_loss: 1.0235 - val_acc: 0.8624\n",
      "Epoch 578/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0453 - acc: 0.9851 - val_loss: 1.0851 - val_acc: 0.8612\n",
      "Epoch 579/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0497 - acc: 0.9838 - val_loss: 1.0944 - val_acc: 0.8574\n",
      "Epoch 580/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.9846INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0463 - acc: 0.9846 - val_loss: 0.9730 - val_acc: 0.8634\n",
      "Epoch 581/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0474 - acc: 0.9846 - val_loss: 0.9086 - val_acc: 0.8619\n",
      "Epoch 582/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0453 - acc: 0.9854 - val_loss: 1.0608 - val_acc: 0.8609\n",
      "Epoch 583/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0482 - acc: 0.9847 - val_loss: 0.9390 - val_acc: 0.8617\n",
      "Epoch 584/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0498 - acc: 0.9840 - val_loss: 1.0131 - val_acc: 0.8622\n",
      "Epoch 585/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0451 - acc: 0.9847 - val_loss: 1.0351 - val_acc: 0.8624\n",
      "Epoch 586/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0449 - acc: 0.9858 - val_loss: 0.8707 - val_acc: 0.8621\n",
      "Epoch 587/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0452 - acc: 0.9849 - val_loss: 0.9434 - val_acc: 0.8605\n",
      "Epoch 588/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0446 - acc: 0.9846 - val_loss: 1.1248 - val_acc: 0.8607\n",
      "Epoch 589/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0464 - acc: 0.9850 - val_loss: 1.0399 - val_acc: 0.8612\n",
      "Epoch 590/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9854INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0457 - acc: 0.9854 - val_loss: 1.0782 - val_acc: 0.8650\n",
      "Epoch 591/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0477 - acc: 0.9845 - val_loss: 0.9658 - val_acc: 0.8618\n",
      "Epoch 592/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9855INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0460 - acc: 0.9855 - val_loss: 0.9094 - val_acc: 0.8654\n",
      "Epoch 593/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0455 - acc: 0.9856 - val_loss: 1.0131 - val_acc: 0.8647\n",
      "Epoch 594/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0494 - acc: 0.9840 - val_loss: 1.0549 - val_acc: 0.8566\n",
      "Epoch 595/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0446 - acc: 0.9855 - val_loss: 0.9956 - val_acc: 0.8588\n",
      "Epoch 596/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0467 - acc: 0.9848 - val_loss: 0.9958 - val_acc: 0.8580\n",
      "Epoch 597/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0441 - acc: 0.9851 - val_loss: 1.0906 - val_acc: 0.8637\n",
      "Epoch 598/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0452 - acc: 0.9853 - val_loss: 1.1581 - val_acc: 0.8599\n",
      "Epoch 599/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0485 - acc: 0.9844 - val_loss: 0.9284 - val_acc: 0.8527\n",
      "Epoch 600/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0489 - acc: 0.9848 - val_loss: 1.0382 - val_acc: 0.8548\n",
      "Epoch 601/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0447 - acc: 0.9863INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0447 - acc: 0.9863 - val_loss: 0.9270 - val_acc: 0.8661\n",
      "Epoch 602/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0485 - acc: 0.9846 - val_loss: 0.9121 - val_acc: 0.8629\n",
      "Epoch 603/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.9855INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0450 - acc: 0.9855 - val_loss: 0.9582 - val_acc: 0.8667\n",
      "Epoch 604/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0471 - acc: 0.9849 - val_loss: 0.9927 - val_acc: 0.8533\n",
      "Epoch 605/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0461 - acc: 0.9853 - val_loss: 1.0711 - val_acc: 0.8568\n",
      "Epoch 606/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0439 - acc: 0.9859 - val_loss: 1.0420 - val_acc: 0.8577\n",
      "Epoch 607/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0464 - acc: 0.9844 - val_loss: 1.0342 - val_acc: 0.8621\n",
      "Epoch 608/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0462 - acc: 0.9854 - val_loss: 0.8890 - val_acc: 0.8602\n",
      "Epoch 609/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0444 - acc: 0.9853 - val_loss: 1.0931 - val_acc: 0.8594\n",
      "Epoch 610/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0444 - acc: 0.9860 - val_loss: 0.9558 - val_acc: 0.8617\n",
      "Epoch 611/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0423 - acc: 0.9856 - val_loss: 1.1633 - val_acc: 0.8578\n",
      "Epoch 612/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0469 - acc: 0.9847 - val_loss: 1.1508 - val_acc: 0.8587\n",
      "Epoch 613/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0447 - acc: 0.9848 - val_loss: 1.0146 - val_acc: 0.8583\n",
      "Epoch 614/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0449 - acc: 0.9856 - val_loss: 1.1620 - val_acc: 0.8641\n",
      "Epoch 615/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0418 - acc: 0.9863 - val_loss: 0.9947 - val_acc: 0.8620\n",
      "Epoch 616/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0428 - acc: 0.9860 - val_loss: 1.0299 - val_acc: 0.8613\n",
      "Epoch 617/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0451 - acc: 0.9850 - val_loss: 1.0654 - val_acc: 0.8588\n",
      "Epoch 618/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0462 - acc: 0.9849 - val_loss: 1.0793 - val_acc: 0.8571\n",
      "Epoch 619/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0443 - acc: 0.9859 - val_loss: 0.9585 - val_acc: 0.8634\n",
      "Epoch 620/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0418 - acc: 0.9867 - val_loss: 1.1346 - val_acc: 0.8594\n",
      "Epoch 621/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0463 - acc: 0.9849 - val_loss: 0.9930 - val_acc: 0.8624\n",
      "Epoch 622/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0491 - acc: 0.9851 - val_loss: 0.8887 - val_acc: 0.8632\n",
      "Epoch 623/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0438 - acc: 0.9858 - val_loss: 0.9205 - val_acc: 0.8658\n",
      "Epoch 624/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0425 - acc: 0.9860 - val_loss: 0.9897 - val_acc: 0.8588\n",
      "Epoch 625/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0409 - acc: 0.9866 - val_loss: 1.1402 - val_acc: 0.8589\n",
      "Epoch 626/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0429 - acc: 0.9867 - val_loss: 1.0876 - val_acc: 0.8617\n",
      "Epoch 627/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0433 - acc: 0.9857 - val_loss: 0.9595 - val_acc: 0.8627\n",
      "Epoch 628/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0440 - acc: 0.9858 - val_loss: 0.9340 - val_acc: 0.8616\n",
      "Epoch 629/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0431 - acc: 0.9853 - val_loss: 0.9780 - val_acc: 0.8606\n",
      "Epoch 630/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0452 - acc: 0.9854 - val_loss: 1.0092 - val_acc: 0.8563\n",
      "Epoch 631/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0451 - acc: 0.9855 - val_loss: 1.0513 - val_acc: 0.8566\n",
      "Epoch 632/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0881 - acc: 0.9763 - val_loss: 0.8979 - val_acc: 0.8577\n",
      "Epoch 633/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0489 - acc: 0.9837 - val_loss: 0.9305 - val_acc: 0.8622\n",
      "Epoch 634/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0406 - acc: 0.9867 - val_loss: 0.8819 - val_acc: 0.8610\n",
      "Epoch 635/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9872INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0384 - acc: 0.9872 - val_loss: 0.9465 - val_acc: 0.8678\n",
      "Epoch 636/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0375 - acc: 0.9882 - val_loss: 0.9156 - val_acc: 0.8663\n",
      "Epoch 637/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0381 - acc: 0.9876 - val_loss: 0.9841 - val_acc: 0.8666\n",
      "Epoch 638/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0405 - acc: 0.9868 - val_loss: 0.9871 - val_acc: 0.8618\n",
      "Epoch 639/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0408 - acc: 0.9868 - val_loss: 0.8971 - val_acc: 0.8623\n",
      "Epoch 640/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0410 - acc: 0.9868 - val_loss: 1.0756 - val_acc: 0.8640\n",
      "Epoch 641/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9860 - val_loss: 0.8944 - val_acc: 0.8653\n",
      "Epoch 642/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0432 - acc: 0.9858 - val_loss: 1.0971 - val_acc: 0.8604\n",
      "Epoch 643/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0426 - acc: 0.9861 - val_loss: 0.9809 - val_acc: 0.8644\n",
      "Epoch 644/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0443 - acc: 0.9851 - val_loss: 1.0985 - val_acc: 0.8632\n",
      "Epoch 645/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0470 - acc: 0.9844 - val_loss: 0.8923 - val_acc: 0.8598\n",
      "Epoch 646/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9862 - val_loss: 1.2086 - val_acc: 0.8584\n",
      "Epoch 647/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0438 - acc: 0.9858 - val_loss: 1.0029 - val_acc: 0.8622\n",
      "Epoch 648/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0411 - acc: 0.9864 - val_loss: 1.2099 - val_acc: 0.8583\n",
      "Epoch 649/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0452 - acc: 0.9853 - val_loss: 1.1171 - val_acc: 0.8645\n",
      "Epoch 650/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0410 - acc: 0.9869 - val_loss: 1.1359 - val_acc: 0.8624\n",
      "Epoch 651/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0412 - acc: 0.9867 - val_loss: 1.1458 - val_acc: 0.8571\n",
      "Epoch 652/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0434 - acc: 0.9860 - val_loss: 0.9583 - val_acc: 0.8599\n",
      "Epoch 653/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0434 - acc: 0.9865 - val_loss: 1.1461 - val_acc: 0.8560\n",
      "Epoch 654/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.9788 - val_acc: 0.8614\n",
      "Epoch 655/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 0.9773 - val_acc: 0.8601\n",
      "Epoch 656/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0432 - acc: 0.9862 - val_loss: 1.1565 - val_acc: 0.8612\n",
      "Epoch 657/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0444 - acc: 0.9857 - val_loss: 1.0633 - val_acc: 0.8600\n",
      "Epoch 658/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0401 - acc: 0.9866 - val_loss: 1.1612 - val_acc: 0.8658\n",
      "Epoch 659/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0418 - acc: 0.9865 - val_loss: 1.1839 - val_acc: 0.8587\n",
      "Epoch 660/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0454 - acc: 0.9852 - val_loss: 0.9378 - val_acc: 0.8634\n",
      "Epoch 661/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0403 - acc: 0.9866 - val_loss: 1.3121 - val_acc: 0.8598\n",
      "Epoch 662/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0441 - acc: 0.9858 - val_loss: 1.1738 - val_acc: 0.8606\n",
      "Epoch 663/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0403 - acc: 0.9872 - val_loss: 1.1340 - val_acc: 0.8619\n",
      "Epoch 664/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0445 - acc: 0.9860 - val_loss: 0.8614 - val_acc: 0.8644\n",
      "Epoch 665/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0426 - acc: 0.9860 - val_loss: 1.0696 - val_acc: 0.8627\n",
      "Epoch 666/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0441 - acc: 0.9863 - val_loss: 1.1504 - val_acc: 0.8612\n",
      "Epoch 667/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0417 - acc: 0.9868 - val_loss: 1.0014 - val_acc: 0.8574\n",
      "Epoch 668/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0447 - acc: 0.9855 - val_loss: 1.0573 - val_acc: 0.8606\n",
      "Epoch 669/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0405 - acc: 0.9873 - val_loss: 1.1171 - val_acc: 0.8641\n",
      "Epoch 670/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0448 - acc: 0.9857 - val_loss: 0.8038 - val_acc: 0.8574\n",
      "Epoch 671/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0424 - acc: 0.9869 - val_loss: 1.0742 - val_acc: 0.8589\n",
      "Epoch 672/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0410 - acc: 0.9874 - val_loss: 1.1658 - val_acc: 0.8579\n",
      "Epoch 673/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0436 - acc: 0.9858 - val_loss: 1.0425 - val_acc: 0.8574\n",
      "Epoch 674/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0408 - acc: 0.9876 - val_loss: 1.1015 - val_acc: 0.8621\n",
      "Epoch 675/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0386 - acc: 0.9878 - val_loss: 1.1510 - val_acc: 0.8598\n",
      "Epoch 676/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0387 - acc: 0.9879 - val_loss: 1.0892 - val_acc: 0.8637\n",
      "Epoch 677/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0424 - acc: 0.9860 - val_loss: 1.0981 - val_acc: 0.8665\n",
      "Epoch 678/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0400 - acc: 0.9872 - val_loss: 1.1602 - val_acc: 0.8597\n",
      "Epoch 679/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0416 - acc: 0.9860 - val_loss: 1.3042 - val_acc: 0.8612\n",
      "Epoch 680/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9862 - val_loss: 1.2750 - val_acc: 0.8588\n",
      "Epoch 681/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0447 - acc: 0.9856 - val_loss: 1.0466 - val_acc: 0.8592\n",
      "Epoch 682/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0402 - acc: 0.9871 - val_loss: 1.2524 - val_acc: 0.8598\n",
      "Epoch 683/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0448 - acc: 0.9858 - val_loss: 1.4563 - val_acc: 0.8524\n",
      "Epoch 684/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0441 - acc: 0.9859 - val_loss: 1.2975 - val_acc: 0.8592\n",
      "Epoch 685/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0426 - acc: 0.9859 - val_loss: 1.4227 - val_acc: 0.8585\n",
      "Epoch 686/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0428 - acc: 0.9862 - val_loss: 1.0781 - val_acc: 0.8622\n",
      "Epoch 687/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9869 - val_loss: 1.0948 - val_acc: 0.8637\n",
      "Epoch 688/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9854 - val_loss: 1.3026 - val_acc: 0.8642\n",
      "Epoch 689/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9866 - val_loss: 1.1339 - val_acc: 0.8606\n",
      "Epoch 690/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0408 - acc: 0.9869 - val_loss: 1.1354 - val_acc: 0.8627\n",
      "Epoch 691/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0416 - acc: 0.9865 - val_loss: 1.0543 - val_acc: 0.8627\n",
      "Epoch 692/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0415 - acc: 0.9865 - val_loss: 1.2519 - val_acc: 0.8614\n",
      "Epoch 693/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0415 - acc: 0.9863 - val_loss: 1.2151 - val_acc: 0.8612\n",
      "Epoch 694/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0444 - acc: 0.9858 - val_loss: 1.5681 - val_acc: 0.8620\n",
      "Epoch 695/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9869 - val_loss: 1.4718 - val_acc: 0.8588\n",
      "Epoch 696/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0440 - acc: 0.9860 - val_loss: 1.3606 - val_acc: 0.8596\n",
      "Epoch 697/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0411 - acc: 0.9867 - val_loss: 1.8319 - val_acc: 0.8592\n",
      "Epoch 698/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0417 - acc: 0.9865 - val_loss: 1.3215 - val_acc: 0.8602\n",
      "Epoch 699/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9859 - val_loss: 1.2688 - val_acc: 0.8587\n",
      "Epoch 700/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0389 - acc: 0.9872 - val_loss: 1.1794 - val_acc: 0.8591\n",
      "Epoch 701/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0405 - acc: 0.9877 - val_loss: 1.1812 - val_acc: 0.8629\n",
      "Epoch 702/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0420 - acc: 0.9866 - val_loss: 1.2524 - val_acc: 0.8546\n",
      "Epoch 703/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0427 - acc: 0.9857 - val_loss: 1.3077 - val_acc: 0.8566\n",
      "Epoch 704/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0401 - acc: 0.9874 - val_loss: 1.4246 - val_acc: 0.8654\n",
      "Epoch 705/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0396 - acc: 0.9874 - val_loss: 1.1577 - val_acc: 0.8652\n",
      "Epoch 706/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0419 - acc: 0.9866 - val_loss: 1.0899 - val_acc: 0.8620\n",
      "Epoch 707/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0430 - acc: 0.9863 - val_loss: 1.2024 - val_acc: 0.8627\n",
      "Epoch 708/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0402 - acc: 0.9864INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0402 - acc: 0.9864 - val_loss: 1.0193 - val_acc: 0.8688\n",
      "Epoch 709/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0424 - acc: 0.9867 - val_loss: 1.1516 - val_acc: 0.8539\n",
      "Epoch 710/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0428 - acc: 0.9863 - val_loss: 1.0475 - val_acc: 0.8515\n",
      "Epoch 711/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0421 - acc: 0.9865 - val_loss: 1.1730 - val_acc: 0.8603\n",
      "Epoch 712/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0398 - acc: 0.9869 - val_loss: 1.1061 - val_acc: 0.8646\n",
      "Epoch 713/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0419 - acc: 0.9866 - val_loss: 1.0276 - val_acc: 0.8674\n",
      "Epoch 714/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0377 - acc: 0.9873 - val_loss: 1.2182 - val_acc: 0.8630\n",
      "Epoch 715/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0401 - acc: 0.9874 - val_loss: 1.1653 - val_acc: 0.8573\n",
      "Epoch 716/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0407 - acc: 0.9870 - val_loss: 1.1622 - val_acc: 0.8640\n",
      "Epoch 717/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0378 - acc: 0.9873 - val_loss: 1.3688 - val_acc: 0.8657\n",
      "Epoch 718/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0395 - acc: 0.9872 - val_loss: 1.1751 - val_acc: 0.8617\n",
      "Epoch 719/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0442 - acc: 0.9861 - val_loss: 1.1167 - val_acc: 0.8623\n",
      "Epoch 720/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0378 - acc: 0.9878 - val_loss: 1.2268 - val_acc: 0.8672\n",
      "Epoch 721/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0430 - acc: 0.9869 - val_loss: 1.5094 - val_acc: 0.8663\n",
      "Epoch 722/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0390 - acc: 0.9866 - val_loss: 1.3436 - val_acc: 0.8620\n",
      "Epoch 723/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0380 - acc: 0.9880 - val_loss: 1.2636 - val_acc: 0.8664\n",
      "Epoch 724/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0404 - acc: 0.9875 - val_loss: 1.1566 - val_acc: 0.8661\n",
      "Epoch 725/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0380 - acc: 0.9878 - val_loss: 1.2646 - val_acc: 0.8580\n",
      "Epoch 726/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0418 - acc: 0.9868 - val_loss: 1.1356 - val_acc: 0.8673\n",
      "Epoch 727/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0405 - acc: 0.9867 - val_loss: 1.2770 - val_acc: 0.8635\n",
      "Epoch 728/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0398 - acc: 0.9877 - val_loss: 1.3038 - val_acc: 0.8639\n",
      "Epoch 729/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0428 - acc: 0.9860 - val_loss: 1.2061 - val_acc: 0.8649\n",
      "Epoch 730/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0380 - acc: 0.9876 - val_loss: 1.3867 - val_acc: 0.8591\n",
      "Epoch 731/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0416 - acc: 0.9867 - val_loss: 1.4212 - val_acc: 0.8592\n",
      "Epoch 732/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0465 - acc: 0.9852 - val_loss: 1.1847 - val_acc: 0.8645\n",
      "Epoch 733/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0416 - acc: 0.9870 - val_loss: 1.2830 - val_acc: 0.8604\n",
      "Epoch 734/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0388 - acc: 0.9874 - val_loss: 1.2773 - val_acc: 0.8606\n",
      "Epoch 735/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0402 - acc: 0.9878 - val_loss: 1.3781 - val_acc: 0.8627\n",
      "Epoch 736/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0531 - acc: 0.9838 - val_loss: 1.0454 - val_acc: 0.8618\n",
      "Epoch 737/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0361 - acc: 0.9879 - val_loss: 1.1741 - val_acc: 0.8624\n",
      "Epoch 738/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0377 - acc: 0.9876 - val_loss: 1.5475 - val_acc: 0.8648\n",
      "Epoch 739/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0378 - acc: 0.9878 - val_loss: 1.4979 - val_acc: 0.8603\n",
      "Epoch 740/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0459 - acc: 0.9850 - val_loss: 1.1283 - val_acc: 0.8640\n",
      "Epoch 741/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0345 - acc: 0.9889 - val_loss: 1.3986 - val_acc: 0.8627\n",
      "Epoch 742/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0382 - acc: 0.9873 - val_loss: 1.6702 - val_acc: 0.8650\n",
      "Epoch 743/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 1.2783 - val_acc: 0.8657\n",
      "Epoch 744/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 1.4862 - val_acc: 0.8647\n",
      "Epoch 745/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0396 - acc: 0.9879 - val_loss: 1.4955 - val_acc: 0.8630\n",
      "Epoch 746/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0375 - acc: 0.9881 - val_loss: 1.5276 - val_acc: 0.8666\n",
      "Epoch 747/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9877 - val_loss: 1.0839 - val_acc: 0.8583\n",
      "Epoch 748/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0417 - acc: 0.9866 - val_loss: 1.2130 - val_acc: 0.8519\n",
      "Epoch 749/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0400 - acc: 0.9866 - val_loss: 1.2899 - val_acc: 0.8628\n",
      "Epoch 750/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 1.3314 - val_acc: 0.8560\n",
      "Epoch 751/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0419 - acc: 0.9870 - val_loss: 1.6458 - val_acc: 0.8678\n",
      "Epoch 752/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0376 - acc: 0.9876 - val_loss: 1.4056 - val_acc: 0.8674\n",
      "Epoch 753/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0391 - acc: 0.9873 - val_loss: 1.4211 - val_acc: 0.8658\n",
      "Epoch 754/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0403 - acc: 0.9872 - val_loss: 1.1138 - val_acc: 0.8602\n",
      "Epoch 755/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0373 - acc: 0.9880 - val_loss: 1.4306 - val_acc: 0.8574\n",
      "Epoch 756/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0390 - acc: 0.9874 - val_loss: 1.3738 - val_acc: 0.8680\n",
      "Epoch 757/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0397 - acc: 0.9872 - val_loss: 1.5253 - val_acc: 0.8623\n",
      "Epoch 758/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0404 - acc: 0.9872 - val_loss: 1.4298 - val_acc: 0.8580\n",
      "Epoch 759/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0405 - acc: 0.9871INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0405 - acc: 0.9871 - val_loss: 1.1375 - val_acc: 0.8691\n",
      "Epoch 760/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0386 - acc: 0.9880 - val_loss: 1.3271 - val_acc: 0.8634\n",
      "Epoch 761/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0383 - acc: 0.9878 - val_loss: 1.2562 - val_acc: 0.8641\n",
      "Epoch 762/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0395 - acc: 0.9878 - val_loss: 1.7520 - val_acc: 0.8648\n",
      "Epoch 763/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0426 - acc: 0.9863 - val_loss: 1.4119 - val_acc: 0.8663\n",
      "Epoch 764/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0388 - acc: 0.9878INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0388 - acc: 0.9878 - val_loss: 1.2972 - val_acc: 0.8701\n",
      "Epoch 765/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0416 - acc: 0.9873 - val_loss: 1.4293 - val_acc: 0.8610\n",
      "Epoch 766/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0391 - acc: 0.9871 - val_loss: 1.5865 - val_acc: 0.8623\n",
      "Epoch 767/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9890 - val_loss: 1.9157 - val_acc: 0.8615\n",
      "Epoch 768/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0435 - acc: 0.9862 - val_loss: 1.2441 - val_acc: 0.8630\n",
      "Epoch 769/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9886 - val_loss: 1.8127 - val_acc: 0.8643\n",
      "Epoch 770/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0385 - acc: 0.9876 - val_loss: 1.2383 - val_acc: 0.8607\n",
      "Epoch 771/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0396 - acc: 0.9869 - val_loss: 1.3106 - val_acc: 0.8598\n",
      "Epoch 772/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0429 - acc: 0.9867 - val_loss: 1.2387 - val_acc: 0.8679\n",
      "Epoch 773/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0401 - acc: 0.9868 - val_loss: 1.4429 - val_acc: 0.8603\n",
      "Epoch 774/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0394 - acc: 0.9868 - val_loss: 1.2842 - val_acc: 0.8638\n",
      "Epoch 775/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0374 - acc: 0.9880 - val_loss: 1.2173 - val_acc: 0.8648\n",
      "Epoch 776/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0427 - acc: 0.9867 - val_loss: 1.2530 - val_acc: 0.8610\n",
      "Epoch 777/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0373 - acc: 0.9874 - val_loss: 1.4123 - val_acc: 0.8679\n",
      "Epoch 778/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0414 - acc: 0.9875 - val_loss: 1.0195 - val_acc: 0.8697\n",
      "Epoch 779/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0399 - acc: 0.9867 - val_loss: 1.0591 - val_acc: 0.8634\n",
      "Epoch 780/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0364 - acc: 0.9883 - val_loss: 1.1964 - val_acc: 0.8606\n",
      "Epoch 781/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0732 - acc: 0.9788 - val_loss: 0.9960 - val_acc: 0.8580\n",
      "Epoch 782/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0387 - acc: 0.9875 - val_loss: 1.0541 - val_acc: 0.8694\n",
      "Epoch 783/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0356 - acc: 0.9882 - val_loss: 1.1142 - val_acc: 0.8694\n",
      "Epoch 784/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0341 - acc: 0.9892 - val_loss: 1.0829 - val_acc: 0.8663\n",
      "Epoch 785/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0332 - acc: 0.9893 - val_loss: 1.1542 - val_acc: 0.8620\n",
      "Epoch 786/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9887 - val_loss: 1.0304 - val_acc: 0.8641\n",
      "Epoch 787/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9884 - val_loss: 1.0137 - val_acc: 0.8614\n",
      "Epoch 788/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0338 - acc: 0.9892 - val_loss: 1.3460 - val_acc: 0.8640\n",
      "Epoch 789/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0362 - acc: 0.9877 - val_loss: 1.1034 - val_acc: 0.8645\n",
      "Epoch 790/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0358 - acc: 0.9883 - val_loss: 1.1546 - val_acc: 0.8678\n",
      "Epoch 791/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0403 - acc: 0.9871 - val_loss: 1.0743 - val_acc: 0.8661\n",
      "Epoch 792/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0372 - acc: 0.9874 - val_loss: 1.1948 - val_acc: 0.8611\n",
      "Epoch 793/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0365 - acc: 0.9885 - val_loss: 1.4381 - val_acc: 0.8544\n",
      "Epoch 794/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0380 - acc: 0.9876 - val_loss: 1.3583 - val_acc: 0.8673\n",
      "Epoch 795/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0400 - acc: 0.9876 - val_loss: 1.0180 - val_acc: 0.8564\n",
      "Epoch 796/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9872 - val_loss: 1.2300 - val_acc: 0.8653\n",
      "Epoch 797/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0367 - acc: 0.9885 - val_loss: 1.0003 - val_acc: 0.8654\n",
      "Epoch 798/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.9887 - val_loss: 1.3180 - val_acc: 0.8616\n",
      "Epoch 799/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0381 - acc: 0.9885 - val_loss: 1.0919 - val_acc: 0.8638\n",
      "Epoch 800/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0364 - acc: 0.9883 - val_loss: 1.2561 - val_acc: 0.8593\n",
      "Epoch 801/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9887 - val_loss: 1.7999 - val_acc: 0.8641\n",
      "Epoch 802/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0439 - acc: 0.9863 - val_loss: 1.1477 - val_acc: 0.8682\n",
      "Epoch 803/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0359 - acc: 0.9881 - val_loss: 1.3867 - val_acc: 0.8582\n",
      "Epoch 804/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0356 - acc: 0.9885 - val_loss: 1.5416 - val_acc: 0.8595\n",
      "Epoch 805/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0411 - acc: 0.9870 - val_loss: 1.2198 - val_acc: 0.8583\n",
      "Epoch 806/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0364 - acc: 0.9881 - val_loss: 1.5640 - val_acc: 0.8604\n",
      "Epoch 807/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0354 - acc: 0.9887 - val_loss: 1.3766 - val_acc: 0.8649\n",
      "Epoch 808/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0363 - acc: 0.9888 - val_loss: 1.7271 - val_acc: 0.8605\n",
      "Epoch 809/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0370 - acc: 0.9878 - val_loss: 1.6532 - val_acc: 0.8391\n",
      "Epoch 810/2000\n",
      "625/625 [==============================] - 13s 16ms/step - loss: 0.0394 - acc: 0.9873 - val_loss: 1.1562 - val_acc: 0.8678\n",
      "Epoch 811/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0375 - acc: 0.9880 - val_loss: 1.5792 - val_acc: 0.8643\n",
      "Epoch 812/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0376 - acc: 0.9876 - val_loss: 1.7984 - val_acc: 0.8672\n",
      "Epoch 813/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0374 - acc: 0.9881 - val_loss: 1.1404 - val_acc: 0.8666\n",
      "Epoch 814/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9873 - val_loss: 0.9707 - val_acc: 0.8623\n",
      "Epoch 815/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0383 - acc: 0.9877 - val_loss: 1.2690 - val_acc: 0.8628\n",
      "Epoch 816/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9894 - val_loss: 1.3575 - val_acc: 0.8610\n",
      "Epoch 817/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0462 - acc: 0.9856 - val_loss: 0.9848 - val_acc: 0.8654\n",
      "Epoch 818/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0392 - acc: 0.9875 - val_loss: 1.0590 - val_acc: 0.8603\n",
      "Epoch 819/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9877 - val_loss: 1.2217 - val_acc: 0.8652\n",
      "Epoch 820/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9882INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0381 - acc: 0.9882 - val_loss: 1.0518 - val_acc: 0.8715\n",
      "Epoch 821/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0349 - acc: 0.9888 - val_loss: 1.3580 - val_acc: 0.8660\n",
      "Epoch 822/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9881 - val_loss: 1.5647 - val_acc: 0.8654\n",
      "Epoch 823/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9883 - val_loss: 1.7596 - val_acc: 0.8656\n",
      "Epoch 824/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0372 - acc: 0.9884 - val_loss: 1.2355 - val_acc: 0.8644\n",
      "Epoch 825/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0390 - acc: 0.9878 - val_loss: 1.4578 - val_acc: 0.8645\n",
      "Epoch 826/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9884 - val_loss: 1.3449 - val_acc: 0.8612\n",
      "Epoch 827/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0354 - acc: 0.9883 - val_loss: 1.3079 - val_acc: 0.8633\n",
      "Epoch 828/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0368 - acc: 0.9881 - val_loss: 1.7659 - val_acc: 0.8666\n",
      "Epoch 829/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0402 - acc: 0.9872 - val_loss: 1.3234 - val_acc: 0.8646\n",
      "Epoch 830/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.9877 - val_loss: 1.6852 - val_acc: 0.8647\n",
      "Epoch 831/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0374 - acc: 0.9883 - val_loss: 1.3400 - val_acc: 0.8596\n",
      "Epoch 832/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0391 - acc: 0.9880 - val_loss: 1.4322 - val_acc: 0.8670\n",
      "Epoch 833/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9894 - val_loss: 1.4486 - val_acc: 0.8631\n",
      "Epoch 834/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0366 - acc: 0.9884 - val_loss: 1.6133 - val_acc: 0.8614\n",
      "Epoch 835/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0360 - acc: 0.9889 - val_loss: 1.5457 - val_acc: 0.8635\n",
      "Epoch 836/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0490 - acc: 0.9852 - val_loss: 1.9853 - val_acc: 0.8636\n",
      "Epoch 837/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0386 - acc: 0.9880 - val_loss: 1.6697 - val_acc: 0.8649\n",
      "Epoch 838/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0353 - acc: 0.9895 - val_loss: 1.3975 - val_acc: 0.8607\n",
      "Epoch 839/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0397 - acc: 0.9873 - val_loss: 1.3718 - val_acc: 0.8683\n",
      "Epoch 840/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0338 - acc: 0.9892 - val_loss: 1.2135 - val_acc: 0.8655\n",
      "Epoch 841/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9889 - val_loss: 1.0587 - val_acc: 0.8677\n",
      "Epoch 842/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0378 - acc: 0.9877 - val_loss: 1.4365 - val_acc: 0.8686\n",
      "Epoch 843/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0367 - acc: 0.9879 - val_loss: 1.4508 - val_acc: 0.8711\n",
      "Epoch 844/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0400 - acc: 0.9871 - val_loss: 1.2832 - val_acc: 0.8651\n",
      "Epoch 845/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0394 - acc: 0.9882 - val_loss: 1.0736 - val_acc: 0.8683\n",
      "Epoch 846/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0339 - acc: 0.9888 - val_loss: 1.6083 - val_acc: 0.8610\n",
      "Epoch 847/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9871 - val_loss: 1.0911 - val_acc: 0.8659\n",
      "Epoch 848/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9884 - val_loss: 1.5832 - val_acc: 0.8605\n",
      "Epoch 849/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0364 - acc: 0.9884 - val_loss: 1.1345 - val_acc: 0.8622\n",
      "Epoch 850/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 1.3421 - val_acc: 0.8646\n",
      "Epoch 851/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9891 - val_loss: 1.4659 - val_acc: 0.8622\n",
      "Epoch 852/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.9884 - val_loss: 1.1653 - val_acc: 0.8686\n",
      "Epoch 853/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9887 - val_loss: 1.4805 - val_acc: 0.8589\n",
      "Epoch 854/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9881 - val_loss: 1.4690 - val_acc: 0.8617\n",
      "Epoch 855/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0366 - acc: 0.9886 - val_loss: 1.5163 - val_acc: 0.8680\n",
      "Epoch 856/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0363 - acc: 0.9884 - val_loss: 1.5691 - val_acc: 0.8611\n",
      "Epoch 857/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0395 - acc: 0.9869 - val_loss: 1.6626 - val_acc: 0.8634\n",
      "Epoch 858/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0426 - acc: 0.9875 - val_loss: 1.0776 - val_acc: 0.8643\n",
      "Epoch 859/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0354 - acc: 0.9887 - val_loss: 1.2105 - val_acc: 0.8681\n",
      "Epoch 860/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9890 - val_loss: 1.6201 - val_acc: 0.8680\n",
      "Epoch 861/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0373 - acc: 0.9883 - val_loss: 1.2914 - val_acc: 0.8679\n",
      "Epoch 862/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9881 - val_loss: 1.7654 - val_acc: 0.8621\n",
      "Epoch 863/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0405 - acc: 0.9871 - val_loss: 1.2064 - val_acc: 0.8648\n",
      "Epoch 864/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9884 - val_loss: 1.7532 - val_acc: 0.8628\n",
      "Epoch 865/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0361 - acc: 0.9884 - val_loss: 1.3778 - val_acc: 0.8682\n",
      "Epoch 866/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0332 - acc: 0.9887 - val_loss: 1.4260 - val_acc: 0.8590\n",
      "Epoch 867/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0379 - acc: 0.9880INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0379 - acc: 0.9880 - val_loss: 1.2124 - val_acc: 0.8740\n",
      "Epoch 868/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0341 - acc: 0.9892 - val_loss: 1.2142 - val_acc: 0.8617\n",
      "Epoch 869/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0337 - acc: 0.9892 - val_loss: 1.4493 - val_acc: 0.8653\n",
      "Epoch 870/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0382 - acc: 0.9883 - val_loss: 1.2015 - val_acc: 0.8665\n",
      "Epoch 871/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9885 - val_loss: 1.4787 - val_acc: 0.8705\n",
      "Epoch 872/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9888 - val_loss: 1.6046 - val_acc: 0.8689\n",
      "Epoch 873/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0523 - acc: 0.9846 - val_loss: 1.0926 - val_acc: 0.8548\n",
      "Epoch 874/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0373 - acc: 0.9882 - val_loss: 1.2115 - val_acc: 0.8654\n",
      "Epoch 875/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0333 - acc: 0.9896 - val_loss: 1.5744 - val_acc: 0.8692\n",
      "Epoch 876/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0330 - acc: 0.9894 - val_loss: 1.2389 - val_acc: 0.8702\n",
      "Epoch 877/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9884 - val_loss: 1.0837 - val_acc: 0.8641\n",
      "Epoch 878/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9896 - val_loss: 1.3046 - val_acc: 0.8659\n",
      "Epoch 879/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9897 - val_loss: 1.6951 - val_acc: 0.8643\n",
      "Epoch 880/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0375 - acc: 0.9880 - val_loss: 1.7902 - val_acc: 0.8669\n",
      "Epoch 881/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0382 - acc: 0.9880 - val_loss: 1.7506 - val_acc: 0.8629\n",
      "Epoch 882/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0362 - acc: 0.9886 - val_loss: 1.4310 - val_acc: 0.8693\n",
      "Epoch 883/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9887 - val_loss: 1.4470 - val_acc: 0.8669\n",
      "Epoch 884/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0326 - acc: 0.9902 - val_loss: 1.7519 - val_acc: 0.8612\n",
      "Epoch 885/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.9888 - val_loss: 1.6238 - val_acc: 0.8612\n",
      "Epoch 886/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0346 - acc: 0.9884 - val_loss: 1.5617 - val_acc: 0.8677\n",
      "Epoch 887/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0346 - acc: 0.9889 - val_loss: 1.6897 - val_acc: 0.8723\n",
      "Epoch 888/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0383 - acc: 0.9888 - val_loss: 1.5883 - val_acc: 0.8710\n",
      "Epoch 889/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0338 - acc: 0.9886 - val_loss: 1.7508 - val_acc: 0.8634\n",
      "Epoch 890/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0437 - acc: 0.9860 - val_loss: 1.2066 - val_acc: 0.8676\n",
      "Epoch 891/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0490 - acc: 0.9849 - val_loss: 1.2078 - val_acc: 0.8643\n",
      "Epoch 892/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0351 - acc: 0.9883 - val_loss: 1.3078 - val_acc: 0.8675\n",
      "Epoch 893/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0308 - acc: 0.9903 - val_loss: 1.4146 - val_acc: 0.8733\n",
      "Epoch 894/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0326 - acc: 0.9899 - val_loss: 1.7677 - val_acc: 0.8680\n",
      "Epoch 895/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0373 - acc: 0.9883 - val_loss: 1.0984 - val_acc: 0.8688\n",
      "Epoch 896/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0378 - acc: 0.9878 - val_loss: 1.6197 - val_acc: 0.8722\n",
      "Epoch 897/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0328 - acc: 0.9895 - val_loss: 1.8828 - val_acc: 0.8680\n",
      "Epoch 898/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0388 - acc: 0.9880 - val_loss: 1.5341 - val_acc: 0.8678\n",
      "Epoch 899/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0389 - acc: 0.9882 - val_loss: 1.5945 - val_acc: 0.8683\n",
      "Epoch 900/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0351 - acc: 0.9881 - val_loss: 1.4602 - val_acc: 0.8674\n",
      "Epoch 901/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9895 - val_loss: 1.6937 - val_acc: 0.8686\n",
      "Epoch 902/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0325 - acc: 0.9893 - val_loss: 1.5591 - val_acc: 0.8687\n",
      "Epoch 903/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0330 - acc: 0.9885 - val_loss: 1.7001 - val_acc: 0.8625\n",
      "Epoch 904/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0341 - acc: 0.9892 - val_loss: 1.4744 - val_acc: 0.8597\n",
      "Epoch 905/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0384 - acc: 0.9875 - val_loss: 1.5100 - val_acc: 0.8662\n",
      "Epoch 906/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0356 - acc: 0.9889 - val_loss: 1.3065 - val_acc: 0.8682\n",
      "Epoch 907/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9895 - val_loss: 1.0548 - val_acc: 0.8670\n",
      "Epoch 908/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0337 - acc: 0.9890 - val_loss: 1.1833 - val_acc: 0.8684\n",
      "Epoch 909/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0332 - acc: 0.9892 - val_loss: 1.8618 - val_acc: 0.8649\n",
      "Epoch 910/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 1.8627 - val_acc: 0.8701\n",
      "Epoch 911/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0393 - acc: 0.9876 - val_loss: 1.2423 - val_acc: 0.8644\n",
      "Epoch 912/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0353 - acc: 0.9886 - val_loss: 1.4533 - val_acc: 0.8650\n",
      "Epoch 913/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0350 - acc: 0.9887 - val_loss: 1.3985 - val_acc: 0.8661\n",
      "Epoch 914/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0359 - acc: 0.9887 - val_loss: 1.8880 - val_acc: 0.8646\n",
      "Epoch 915/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0374 - acc: 0.9881 - val_loss: 1.1341 - val_acc: 0.8680\n",
      "Epoch 916/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0333 - acc: 0.9891 - val_loss: 1.6742 - val_acc: 0.8661\n",
      "Epoch 917/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0353 - acc: 0.9886 - val_loss: 1.7019 - val_acc: 0.8599\n",
      "Epoch 918/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0391 - acc: 0.9878 - val_loss: 1.6440 - val_acc: 0.8618\n",
      "Epoch 919/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 2.2200 - val_acc: 0.8630\n",
      "Epoch 920/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9887 - val_loss: 2.1005 - val_acc: 0.8623\n",
      "Epoch 921/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9894 - val_loss: 2.6514 - val_acc: 0.8662\n",
      "Epoch 922/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0343 - acc: 0.9893 - val_loss: 2.1411 - val_acc: 0.8668\n",
      "Epoch 923/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0346 - acc: 0.9891 - val_loss: 1.3979 - val_acc: 0.8628\n",
      "Epoch 924/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9886 - val_loss: 1.5460 - val_acc: 0.8664\n",
      "Epoch 925/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9888 - val_loss: 1.4476 - val_acc: 0.8657\n",
      "Epoch 926/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0371 - acc: 0.9886 - val_loss: 2.1782 - val_acc: 0.8683\n",
      "Epoch 927/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0322 - acc: 0.9895 - val_loss: 2.1497 - val_acc: 0.8654\n",
      "Epoch 928/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0537 - acc: 0.9830 - val_loss: 1.1917 - val_acc: 0.8585\n",
      "Epoch 929/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0391 - acc: 0.9876 - val_loss: 1.7809 - val_acc: 0.8688\n",
      "Epoch 930/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0307 - acc: 0.9898 - val_loss: 1.8700 - val_acc: 0.8634\n",
      "Epoch 931/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0374 - acc: 0.9882 - val_loss: 1.7024 - val_acc: 0.8687\n",
      "Epoch 932/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0328 - acc: 0.9897 - val_loss: 1.4078 - val_acc: 0.8662\n",
      "Epoch 933/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 1.7565 - val_acc: 0.8655\n",
      "Epoch 934/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0321 - acc: 0.9903 - val_loss: 2.3375 - val_acc: 0.8676\n",
      "Epoch 935/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0318 - acc: 0.9898 - val_loss: 1.7712 - val_acc: 0.8694\n",
      "Epoch 936/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9905 - val_loss: 1.6259 - val_acc: 0.8688\n",
      "Epoch 937/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0359 - acc: 0.9886 - val_loss: 1.3433 - val_acc: 0.8614\n",
      "Epoch 938/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0338 - acc: 0.9892 - val_loss: 1.3834 - val_acc: 0.8710\n",
      "Epoch 939/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0347 - acc: 0.9892 - val_loss: 1.3061 - val_acc: 0.8719\n",
      "Epoch 940/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9894 - val_loss: 1.4550 - val_acc: 0.8621\n",
      "Epoch 941/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0317 - acc: 0.9897 - val_loss: 1.6912 - val_acc: 0.8659\n",
      "Epoch 942/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0353 - acc: 0.9894 - val_loss: 1.2821 - val_acc: 0.8704\n",
      "Epoch 943/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0320 - acc: 0.9898 - val_loss: 1.3883 - val_acc: 0.8665\n",
      "Epoch 944/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0334 - acc: 0.9894 - val_loss: 1.5110 - val_acc: 0.8670\n",
      "Epoch 945/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0386 - acc: 0.9876 - val_loss: 1.3974 - val_acc: 0.8625\n",
      "Epoch 946/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0349 - acc: 0.9890 - val_loss: 1.6290 - val_acc: 0.8661\n",
      "Epoch 947/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9893 - val_loss: 1.6788 - val_acc: 0.8627\n",
      "Epoch 948/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0344 - acc: 0.9891 - val_loss: 1.2450 - val_acc: 0.8624\n",
      "Epoch 949/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9893 - val_loss: 1.2742 - val_acc: 0.8625\n",
      "Epoch 950/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9888 - val_loss: 1.2684 - val_acc: 0.8676\n",
      "Epoch 951/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9895 - val_loss: 2.3643 - val_acc: 0.8639\n",
      "Epoch 952/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9894 - val_loss: 2.1079 - val_acc: 0.8602\n",
      "Epoch 953/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0427 - acc: 0.9870 - val_loss: 1.6020 - val_acc: 0.8678\n",
      "Epoch 954/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0321 - acc: 0.9900 - val_loss: 1.9207 - val_acc: 0.8673\n",
      "Epoch 955/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0427 - acc: 0.9877 - val_loss: 1.3908 - val_acc: 0.8695\n",
      "Epoch 956/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0380 - acc: 0.9880 - val_loss: 1.1102 - val_acc: 0.8723\n",
      "Epoch 957/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.9901 - val_loss: 1.3535 - val_acc: 0.8675\n",
      "Epoch 958/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0322 - acc: 0.9897 - val_loss: 1.4775 - val_acc: 0.8714\n",
      "Epoch 959/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.9890INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0354 - acc: 0.9890 - val_loss: 1.3644 - val_acc: 0.8741\n",
      "Epoch 960/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0325 - acc: 0.9896 - val_loss: 1.4113 - val_acc: 0.8693\n",
      "Epoch 961/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0467 - acc: 0.9863 - val_loss: 1.2036 - val_acc: 0.8703\n",
      "Epoch 962/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9888 - val_loss: 1.2952 - val_acc: 0.8658\n",
      "Epoch 963/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0310 - acc: 0.9906 - val_loss: 1.2605 - val_acc: 0.8663\n",
      "Epoch 964/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0291 - acc: 0.9909 - val_loss: 1.6067 - val_acc: 0.8698\n",
      "Epoch 965/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 1.5201 - val_acc: 0.8670\n",
      "Epoch 966/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0320 - acc: 0.9899 - val_loss: 1.4994 - val_acc: 0.8687\n",
      "Epoch 967/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9891 - val_loss: 1.5679 - val_acc: 0.8707\n",
      "Epoch 968/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9902 - val_loss: 3.1294 - val_acc: 0.8690\n",
      "Epoch 969/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0349 - acc: 0.9894 - val_loss: 1.4751 - val_acc: 0.8645\n",
      "Epoch 970/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9888 - val_loss: 1.1098 - val_acc: 0.8617\n",
      "Epoch 971/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9886 - val_loss: 1.6370 - val_acc: 0.8676\n",
      "Epoch 972/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0394 - acc: 0.9875 - val_loss: 1.4844 - val_acc: 0.8692\n",
      "Epoch 973/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0298 - acc: 0.9903 - val_loss: 1.2251 - val_acc: 0.8658\n",
      "Epoch 974/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9905 - val_loss: 1.1892 - val_acc: 0.8710\n",
      "Epoch 975/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0308 - acc: 0.9902 - val_loss: 1.4423 - val_acc: 0.8590\n",
      "Epoch 976/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0358 - acc: 0.9892 - val_loss: 1.9983 - val_acc: 0.8717\n",
      "Epoch 977/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0322 - acc: 0.9896 - val_loss: 1.8758 - val_acc: 0.8652\n",
      "Epoch 978/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0387 - acc: 0.9881 - val_loss: 1.1756 - val_acc: 0.8663\n",
      "Epoch 979/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9893 - val_loss: 1.4300 - val_acc: 0.8717\n",
      "Epoch 980/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0308 - acc: 0.9897 - val_loss: 2.0434 - val_acc: 0.8688\n",
      "Epoch 981/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9897 - val_loss: 1.7217 - val_acc: 0.8713\n",
      "Epoch 982/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0331 - acc: 0.9899INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0331 - acc: 0.9899 - val_loss: 2.0938 - val_acc: 0.8743\n",
      "Epoch 983/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9905 - val_loss: 2.3359 - val_acc: 0.8664\n",
      "Epoch 984/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0385 - acc: 0.9880 - val_loss: 1.8299 - val_acc: 0.8586\n",
      "Epoch 985/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0349 - acc: 0.9888 - val_loss: 1.4647 - val_acc: 0.8692\n",
      "Epoch 986/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0322 - acc: 0.9897 - val_loss: 2.7272 - val_acc: 0.8637\n",
      "Epoch 987/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9897 - val_loss: 1.4751 - val_acc: 0.8656\n",
      "Epoch 988/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0362 - acc: 0.9886 - val_loss: 2.5146 - val_acc: 0.8675\n",
      "Epoch 989/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0346 - acc: 0.9891 - val_loss: 1.8654 - val_acc: 0.8681\n",
      "Epoch 990/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0354 - acc: 0.9884 - val_loss: 1.5001 - val_acc: 0.8709\n",
      "Epoch 991/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0315 - acc: 0.9897 - val_loss: 1.8248 - val_acc: 0.8672\n",
      "Epoch 992/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0328 - acc: 0.9899 - val_loss: 1.6402 - val_acc: 0.8720\n",
      "Epoch 993/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9904 - val_loss: 2.1563 - val_acc: 0.8652\n",
      "Epoch 994/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0343 - acc: 0.9895 - val_loss: 2.3994 - val_acc: 0.8675\n",
      "Epoch 995/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0349 - acc: 0.9888 - val_loss: 1.5193 - val_acc: 0.8726\n",
      "Epoch 996/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0370 - acc: 0.9881 - val_loss: 1.5056 - val_acc: 0.8622\n",
      "Epoch 997/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0334 - acc: 0.9892INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 19ms/step - loss: 0.0334 - acc: 0.9892 - val_loss: 1.5094 - val_acc: 0.8752\n",
      "Epoch 998/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9901 - val_loss: 1.8204 - val_acc: 0.8686\n",
      "Epoch 999/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0343 - acc: 0.9890 - val_loss: 1.6641 - val_acc: 0.8675\n",
      "Epoch 1000/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0281 - acc: 0.9915 - val_loss: 1.7315 - val_acc: 0.8680\n",
      "Epoch 1001/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0317 - acc: 0.9896 - val_loss: 1.2272 - val_acc: 0.8705\n",
      "Epoch 1002/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0354 - acc: 0.9892 - val_loss: 1.1528 - val_acc: 0.8723\n",
      "Epoch 1003/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0320 - acc: 0.9901 - val_loss: 1.6576 - val_acc: 0.8710\n",
      "Epoch 1004/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9896 - val_loss: 1.8144 - val_acc: 0.8691\n",
      "Epoch 1005/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0342 - acc: 0.9889 - val_loss: 1.4424 - val_acc: 0.8743\n",
      "Epoch 1006/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 1.5954 - val_acc: 0.8668\n",
      "Epoch 1007/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9889 - val_loss: 1.1861 - val_acc: 0.8643\n",
      "Epoch 1008/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0328 - acc: 0.9898 - val_loss: 1.7912 - val_acc: 0.8687\n",
      "Epoch 1009/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9892 - val_loss: 1.7899 - val_acc: 0.8738\n",
      "Epoch 1010/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0318 - acc: 0.9902 - val_loss: 1.4575 - val_acc: 0.8635\n",
      "Epoch 1011/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9902 - val_loss: 1.3734 - val_acc: 0.8685\n",
      "Epoch 1012/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9897 - val_loss: 1.4946 - val_acc: 0.8707\n",
      "Epoch 1013/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9899 - val_loss: 1.3215 - val_acc: 0.8629\n",
      "Epoch 1014/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9893 - val_loss: 1.2954 - val_acc: 0.8691\n",
      "Epoch 1015/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9893 - val_loss: 1.2688 - val_acc: 0.8725\n",
      "Epoch 1016/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0341 - acc: 0.9889 - val_loss: 1.9279 - val_acc: 0.8691\n",
      "Epoch 1017/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0421 - acc: 0.9871 - val_loss: 1.0792 - val_acc: 0.8665\n",
      "Epoch 1018/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0315 - acc: 0.9901 - val_loss: 1.4369 - val_acc: 0.8713\n",
      "Epoch 1019/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9904 - val_loss: 1.3331 - val_acc: 0.8665\n",
      "Epoch 1020/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0319 - acc: 0.9900 - val_loss: 1.1819 - val_acc: 0.8726\n",
      "Epoch 1021/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0318 - acc: 0.9899 - val_loss: 1.8663 - val_acc: 0.8736\n",
      "Epoch 1022/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0340 - acc: 0.9895 - val_loss: 1.3735 - val_acc: 0.8736\n",
      "Epoch 1023/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.9898 - val_loss: 1.8235 - val_acc: 0.8687\n",
      "Epoch 1024/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9897 - val_loss: 2.7244 - val_acc: 0.8721\n",
      "Epoch 1025/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0334 - acc: 0.9895 - val_loss: 1.3531 - val_acc: 0.8663\n",
      "Epoch 1026/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9868 - val_loss: 1.2523 - val_acc: 0.8682\n",
      "Epoch 1027/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0306 - acc: 0.9902 - val_loss: 1.6023 - val_acc: 0.8723\n",
      "Epoch 1028/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0317 - acc: 0.9901 - val_loss: 1.4625 - val_acc: 0.8722\n",
      "Epoch 1029/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0343 - acc: 0.9896 - val_loss: 1.5614 - val_acc: 0.8693\n",
      "Epoch 1030/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0299 - acc: 0.9905 - val_loss: 1.7563 - val_acc: 0.8699\n",
      "Epoch 1031/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 1.9046 - val_acc: 0.8711\n",
      "Epoch 1032/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9894 - val_loss: 1.7134 - val_acc: 0.8623\n",
      "Epoch 1033/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 1.4306 - val_acc: 0.8621\n",
      "Epoch 1034/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9891 - val_loss: 1.7299 - val_acc: 0.8678\n",
      "Epoch 1035/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.9901 - val_loss: 2.0515 - val_acc: 0.8626\n",
      "Epoch 1036/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 2.0726 - val_acc: 0.8637\n",
      "Epoch 1037/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0481 - acc: 0.9863 - val_loss: 1.5581 - val_acc: 0.8604\n",
      "Epoch 1038/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0311 - acc: 0.9902 - val_loss: 2.7023 - val_acc: 0.8680\n",
      "Epoch 1039/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0300 - acc: 0.9904 - val_loss: 2.6825 - val_acc: 0.8684\n",
      "Epoch 1040/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0356 - acc: 0.9892 - val_loss: 2.2830 - val_acc: 0.8704\n",
      "Epoch 1041/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 1.8863 - val_acc: 0.8678\n",
      "Epoch 1042/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0430 - acc: 0.9882 - val_loss: 2.9334 - val_acc: 0.8660\n",
      "Epoch 1043/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 2.3584 - val_acc: 0.8694\n",
      "Epoch 1044/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0301 - acc: 0.9905 - val_loss: 1.9644 - val_acc: 0.8589\n",
      "Epoch 1045/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 2.4842 - val_acc: 0.8703\n",
      "Epoch 1046/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0292 - acc: 0.9904 - val_loss: 2.2320 - val_acc: 0.8699\n",
      "Epoch 1047/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0306 - acc: 0.9901 - val_loss: 2.3641 - val_acc: 0.8692\n",
      "Epoch 1048/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0315 - acc: 0.9906 - val_loss: 2.0176 - val_acc: 0.8685\n",
      "Epoch 1049/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0347 - acc: 0.9896 - val_loss: 1.5711 - val_acc: 0.8674\n",
      "Epoch 1050/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 1.5981 - val_acc: 0.8640\n",
      "Epoch 1051/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 3.0901 - val_acc: 0.8688\n",
      "Epoch 1052/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9900 - val_loss: 1.3656 - val_acc: 0.8598\n",
      "Epoch 1053/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0326 - acc: 0.9897 - val_loss: 1.9998 - val_acc: 0.8678\n",
      "Epoch 1054/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9897 - val_loss: 1.8127 - val_acc: 0.8711\n",
      "Epoch 1055/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0290 - acc: 0.9902 - val_loss: 2.0370 - val_acc: 0.8722\n",
      "Epoch 1056/2000\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0318 - acc: 0.9906INFO:tensorflow:Assets written to: /home/michael1017/jinyu/comp4/ckpt2/assets\n",
      "625/625 [==============================] - 14s 18ms/step - loss: 0.0318 - acc: 0.9906 - val_loss: 2.4267 - val_acc: 0.8757\n",
      "Epoch 1057/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9898 - val_loss: 1.8665 - val_acc: 0.8741\n",
      "Epoch 1058/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 2.4099 - val_acc: 0.8709\n",
      "Epoch 1059/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0305 - acc: 0.9899 - val_loss: 3.0675 - val_acc: 0.8662\n",
      "Epoch 1060/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0342 - acc: 0.9896 - val_loss: 1.4466 - val_acc: 0.8618\n",
      "Epoch 1061/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 1.7134 - val_acc: 0.8706\n",
      "Epoch 1062/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9900 - val_loss: 2.3388 - val_acc: 0.8668\n",
      "Epoch 1063/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0401 - acc: 0.9885 - val_loss: 3.0465 - val_acc: 0.8591\n",
      "Epoch 1064/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0355 - acc: 0.9888 - val_loss: 0.9207 - val_acc: 0.8425\n",
      "Epoch 1065/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9889 - val_loss: 1.3234 - val_acc: 0.8652\n",
      "Epoch 1066/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0272 - acc: 0.9915 - val_loss: 1.9154 - val_acc: 0.8719\n",
      "Epoch 1067/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 1.3273 - val_acc: 0.8713\n",
      "Epoch 1068/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0289 - acc: 0.9911 - val_loss: 1.8607 - val_acc: 0.8702\n",
      "Epoch 1069/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0311 - acc: 0.9902 - val_loss: 1.5626 - val_acc: 0.8711\n",
      "Epoch 1070/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0286 - acc: 0.9901 - val_loss: 2.6747 - val_acc: 0.8601\n",
      "Epoch 1071/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0336 - acc: 0.9895 - val_loss: 1.9822 - val_acc: 0.8704\n",
      "Epoch 1072/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0295 - acc: 0.9905 - val_loss: 1.5606 - val_acc: 0.8691\n",
      "Epoch 1073/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9894 - val_loss: 1.8222 - val_acc: 0.8691\n",
      "Epoch 1074/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0366 - acc: 0.9886 - val_loss: 1.8981 - val_acc: 0.8678\n",
      "Epoch 1075/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 1.6183 - val_acc: 0.8674\n",
      "Epoch 1076/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9899 - val_loss: 1.5113 - val_acc: 0.8747\n",
      "Epoch 1077/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0360 - acc: 0.9891 - val_loss: 1.4638 - val_acc: 0.8660\n",
      "Epoch 1078/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 1.6863 - val_acc: 0.8612\n",
      "Epoch 1079/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0275 - acc: 0.9914 - val_loss: 2.0444 - val_acc: 0.8653\n",
      "Epoch 1080/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9899 - val_loss: 1.9555 - val_acc: 0.8691\n",
      "Epoch 1081/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 2.4433 - val_acc: 0.8649\n",
      "Epoch 1082/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9903 - val_loss: 2.4185 - val_acc: 0.8666\n",
      "Epoch 1083/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0352 - acc: 0.9890 - val_loss: 1.5035 - val_acc: 0.8612\n",
      "Epoch 1084/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9903 - val_loss: 2.3934 - val_acc: 0.8668\n",
      "Epoch 1085/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0296 - acc: 0.9906 - val_loss: 2.7253 - val_acc: 0.8666\n",
      "Epoch 1086/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0326 - acc: 0.9896 - val_loss: 1.7259 - val_acc: 0.8645\n",
      "Epoch 1087/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0322 - acc: 0.9896 - val_loss: 1.8058 - val_acc: 0.8641\n",
      "Epoch 1088/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0348 - acc: 0.9886 - val_loss: 2.0764 - val_acc: 0.8671\n",
      "Epoch 1089/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9898 - val_loss: 2.9463 - val_acc: 0.8641\n",
      "Epoch 1090/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0318 - acc: 0.9904 - val_loss: 1.5493 - val_acc: 0.8694\n",
      "Epoch 1091/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0332 - acc: 0.9897 - val_loss: 1.9515 - val_acc: 0.8684\n",
      "Epoch 1092/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 1.0802 - val_acc: 0.8720\n",
      "Epoch 1093/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 1.2506 - val_acc: 0.8709\n",
      "Epoch 1094/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9905 - val_loss: 1.2715 - val_acc: 0.8745\n",
      "Epoch 1095/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0285 - acc: 0.9911 - val_loss: 1.6232 - val_acc: 0.8630\n",
      "Epoch 1096/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 1.6685 - val_acc: 0.8667\n",
      "Epoch 1097/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 1.3648 - val_acc: 0.8674\n",
      "Epoch 1098/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0331 - acc: 0.9907 - val_loss: 1.5943 - val_acc: 0.8717\n",
      "Epoch 1099/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9892 - val_loss: 2.5032 - val_acc: 0.8659\n",
      "Epoch 1100/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0279 - acc: 0.9909 - val_loss: 1.6542 - val_acc: 0.8641\n",
      "Epoch 1101/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9906 - val_loss: 1.3712 - val_acc: 0.8728\n",
      "Epoch 1102/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0300 - acc: 0.9905 - val_loss: 1.4444 - val_acc: 0.8650\n",
      "Epoch 1103/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0294 - acc: 0.9909 - val_loss: 2.1034 - val_acc: 0.8682\n",
      "Epoch 1104/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9898 - val_loss: 1.4586 - val_acc: 0.8586\n",
      "Epoch 1105/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 2.1486 - val_acc: 0.8659\n",
      "Epoch 1106/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0293 - acc: 0.9907 - val_loss: 2.8068 - val_acc: 0.8684\n",
      "Epoch 1107/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0308 - acc: 0.9903 - val_loss: 1.8067 - val_acc: 0.8703\n",
      "Epoch 1108/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0334 - acc: 0.9899 - val_loss: 1.8843 - val_acc: 0.8725\n",
      "Epoch 1109/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0330 - acc: 0.9899 - val_loss: 1.4955 - val_acc: 0.8506\n",
      "Epoch 1110/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0402 - acc: 0.9880 - val_loss: 1.3377 - val_acc: 0.8691\n",
      "Epoch 1111/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0275 - acc: 0.9911 - val_loss: 1.8262 - val_acc: 0.8645\n",
      "Epoch 1112/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0295 - acc: 0.9901 - val_loss: 1.5475 - val_acc: 0.8688\n",
      "Epoch 1113/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0316 - acc: 0.9900 - val_loss: 2.1821 - val_acc: 0.8687\n",
      "Epoch 1114/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0310 - acc: 0.9906 - val_loss: 1.2314 - val_acc: 0.8716\n",
      "Epoch 1115/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0278 - acc: 0.9914 - val_loss: 3.3290 - val_acc: 0.8658\n",
      "Epoch 1116/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0362 - acc: 0.9892 - val_loss: 2.4628 - val_acc: 0.8693\n",
      "Epoch 1117/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 1.4859 - val_acc: 0.8702\n",
      "Epoch 1118/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0290 - acc: 0.9901 - val_loss: 2.0788 - val_acc: 0.8697\n",
      "Epoch 1119/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0306 - acc: 0.9894 - val_loss: 1.6244 - val_acc: 0.8668\n",
      "Epoch 1120/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.9898 - val_loss: 3.3229 - val_acc: 0.8683\n",
      "Epoch 1121/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0319 - acc: 0.9902 - val_loss: 1.0651 - val_acc: 0.8700\n",
      "Epoch 1122/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0281 - acc: 0.9916 - val_loss: 1.6738 - val_acc: 0.8692\n",
      "Epoch 1123/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0293 - acc: 0.9908 - val_loss: 2.6699 - val_acc: 0.8671\n",
      "Epoch 1124/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9904 - val_loss: 3.0259 - val_acc: 0.8672\n",
      "Epoch 1125/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9902 - val_loss: 1.9632 - val_acc: 0.8651\n",
      "Epoch 1126/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0320 - acc: 0.9900 - val_loss: 2.9577 - val_acc: 0.8739\n",
      "Epoch 1127/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 1.6939 - val_acc: 0.8520\n",
      "Epoch 1128/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0363 - acc: 0.9885 - val_loss: 2.7153 - val_acc: 0.8712\n",
      "Epoch 1129/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0293 - acc: 0.9910 - val_loss: 1.5618 - val_acc: 0.8693\n",
      "Epoch 1130/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0282 - acc: 0.9908 - val_loss: 2.1480 - val_acc: 0.8652\n",
      "Epoch 1131/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0311 - acc: 0.9905 - val_loss: 2.4660 - val_acc: 0.8684\n",
      "Epoch 1132/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0275 - acc: 0.9918 - val_loss: 2.1964 - val_acc: 0.8689\n",
      "Epoch 1133/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0521 - acc: 0.9850 - val_loss: 1.3573 - val_acc: 0.8569\n",
      "Epoch 1134/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0389 - acc: 0.9873 - val_loss: 1.6907 - val_acc: 0.8699\n",
      "Epoch 1135/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0280 - acc: 0.9911 - val_loss: 1.8448 - val_acc: 0.8743\n",
      "Epoch 1136/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0287 - acc: 0.9901 - val_loss: 1.9671 - val_acc: 0.8702\n",
      "Epoch 1137/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 2.2661 - val_acc: 0.8739\n",
      "Epoch 1138/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0263 - acc: 0.9916 - val_loss: 2.5474 - val_acc: 0.8708\n",
      "Epoch 1139/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0280 - acc: 0.9913 - val_loss: 2.4773 - val_acc: 0.8694\n",
      "Epoch 1140/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0259 - acc: 0.9915 - val_loss: 2.1192 - val_acc: 0.8744\n",
      "Epoch 1141/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0314 - acc: 0.9897 - val_loss: 1.9798 - val_acc: 0.8678\n",
      "Epoch 1142/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0335 - acc: 0.9899 - val_loss: 1.6145 - val_acc: 0.8651\n",
      "Epoch 1143/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0284 - acc: 0.9902 - val_loss: 2.2353 - val_acc: 0.8722\n",
      "Epoch 1144/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0303 - acc: 0.9901 - val_loss: 1.6275 - val_acc: 0.8727\n",
      "Epoch 1145/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0295 - acc: 0.9911 - val_loss: 2.2259 - val_acc: 0.8575\n",
      "Epoch 1146/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0406 - acc: 0.9888 - val_loss: 1.4698 - val_acc: 0.8673\n",
      "Epoch 1147/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0275 - acc: 0.9913 - val_loss: 1.3244 - val_acc: 0.8723\n",
      "Epoch 1148/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0281 - acc: 0.9915 - val_loss: 1.7939 - val_acc: 0.8723\n",
      "Epoch 1149/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0275 - acc: 0.9917 - val_loss: 2.0668 - val_acc: 0.8685\n",
      "Epoch 1150/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0278 - acc: 0.9912 - val_loss: 3.3105 - val_acc: 0.8700\n",
      "Epoch 1151/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 1.7959 - val_acc: 0.8651\n",
      "Epoch 1152/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0303 - acc: 0.9901 - val_loss: 1.5364 - val_acc: 0.8649\n",
      "Epoch 1153/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0297 - acc: 0.9904 - val_loss: 2.1798 - val_acc: 0.8688\n",
      "Epoch 1154/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0319 - acc: 0.9900 - val_loss: 2.0282 - val_acc: 0.8709\n",
      "Epoch 1155/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0293 - acc: 0.9910 - val_loss: 2.1054 - val_acc: 0.8677\n",
      "Epoch 1156/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9903 - val_loss: 3.4486 - val_acc: 0.8750\n",
      "Epoch 1157/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0324 - acc: 0.9904 - val_loss: 2.8450 - val_acc: 0.8709\n",
      "Epoch 1158/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 2.9689 - val_acc: 0.8692\n",
      "Epoch 1159/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0300 - acc: 0.9908 - val_loss: 2.7388 - val_acc: 0.8679\n",
      "Epoch 1160/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0334 - acc: 0.9897 - val_loss: 2.0770 - val_acc: 0.8660\n",
      "Epoch 1161/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0283 - acc: 0.9907 - val_loss: 3.7448 - val_acc: 0.8694\n",
      "Epoch 1162/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0273 - acc: 0.9912 - val_loss: 3.7595 - val_acc: 0.8603\n",
      "Epoch 1163/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0292 - acc: 0.9910 - val_loss: 4.1771 - val_acc: 0.8740\n",
      "Epoch 1164/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9900 - val_loss: 2.8995 - val_acc: 0.8646\n",
      "Epoch 1165/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0298 - acc: 0.9902 - val_loss: 1.6302 - val_acc: 0.8679\n",
      "Epoch 1166/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0271 - acc: 0.9914 - val_loss: 2.1875 - val_acc: 0.8684\n",
      "Epoch 1167/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0301 - acc: 0.9904 - val_loss: 2.4536 - val_acc: 0.8732\n",
      "Epoch 1168/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0287 - acc: 0.9911 - val_loss: 1.7132 - val_acc: 0.8691\n",
      "Epoch 1169/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0325 - acc: 0.9896 - val_loss: 2.3252 - val_acc: 0.8654\n",
      "Epoch 1170/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 4.2021 - val_acc: 0.8643\n",
      "Epoch 1171/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0269 - acc: 0.9915 - val_loss: 3.3037 - val_acc: 0.8633\n",
      "Epoch 1172/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0330 - acc: 0.9899 - val_loss: 3.5618 - val_acc: 0.8682\n",
      "Epoch 1173/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0451 - acc: 0.9868 - val_loss: 2.8609 - val_acc: 0.8695\n",
      "Epoch 1174/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0298 - acc: 0.9905 - val_loss: 3.8095 - val_acc: 0.8685\n",
      "Epoch 1175/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0323 - acc: 0.9903 - val_loss: 2.9398 - val_acc: 0.8679\n",
      "Epoch 1176/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0425 - acc: 0.9881 - val_loss: 2.4850 - val_acc: 0.8617\n",
      "Epoch 1177/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0284 - acc: 0.9906 - val_loss: 2.1556 - val_acc: 0.8710\n",
      "Epoch 1178/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0288 - acc: 0.9914 - val_loss: 2.2548 - val_acc: 0.8640\n",
      "Epoch 1179/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0292 - acc: 0.9909 - val_loss: 2.1390 - val_acc: 0.8732\n",
      "Epoch 1180/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0267 - acc: 0.9908 - val_loss: 3.0626 - val_acc: 0.8707\n",
      "Epoch 1181/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 3.0779 - val_acc: 0.8636\n",
      "Epoch 1182/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0251 - acc: 0.9920 - val_loss: 3.6426 - val_acc: 0.8716\n",
      "Epoch 1183/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0273 - acc: 0.9911 - val_loss: 2.5327 - val_acc: 0.8721\n",
      "Epoch 1184/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0299 - acc: 0.9905 - val_loss: 4.2725 - val_acc: 0.8695\n",
      "Epoch 1185/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0305 - acc: 0.9905 - val_loss: 2.9874 - val_acc: 0.8704\n",
      "Epoch 1186/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0295 - acc: 0.9908 - val_loss: 2.9431 - val_acc: 0.8727\n",
      "Epoch 1187/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 2.7804 - val_acc: 0.8615\n",
      "Epoch 1188/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0288 - acc: 0.9909 - val_loss: 3.5558 - val_acc: 0.8699\n",
      "Epoch 1189/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0413 - acc: 0.9879 - val_loss: 2.9287 - val_acc: 0.8696\n",
      "Epoch 1190/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 2.8250 - val_acc: 0.8742\n",
      "Epoch 1191/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0264 - acc: 0.9913 - val_loss: 4.7490 - val_acc: 0.8608\n",
      "Epoch 1192/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0316 - acc: 0.9898 - val_loss: 2.7419 - val_acc: 0.8702\n",
      "Epoch 1193/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0291 - acc: 0.9906 - val_loss: 2.7122 - val_acc: 0.8691\n",
      "Epoch 1194/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0293 - acc: 0.9909 - val_loss: 3.4683 - val_acc: 0.8732\n",
      "Epoch 1195/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0300 - acc: 0.9906 - val_loss: 2.8166 - val_acc: 0.8733\n",
      "Epoch 1196/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0366 - acc: 0.9890 - val_loss: 3.3574 - val_acc: 0.8624\n",
      "Epoch 1197/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 2.7708 - val_acc: 0.8729\n",
      "Epoch 1198/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0300 - acc: 0.9905 - val_loss: 2.3575 - val_acc: 0.8667\n",
      "Epoch 1199/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0312 - acc: 0.9906 - val_loss: 3.7327 - val_acc: 0.8702\n",
      "Epoch 1200/2000\n",
      "625/625 [==============================] - 12s 15ms/step - loss: 0.0304 - acc: 0.9904 - val_loss: 1.5609 - val_acc: 0.8506\n",
      "Epoch 1201/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0333 - acc: 0.9896 - val_loss: 1.5666 - val_acc: 0.8723\n",
      "Epoch 1202/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0304 - acc: 0.9907 - val_loss: 1.8781 - val_acc: 0.8682\n",
      "Epoch 1203/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0297 - acc: 0.9903 - val_loss: 2.0542 - val_acc: 0.8662\n",
      "Epoch 1204/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0296 - acc: 0.9907 - val_loss: 2.4981 - val_acc: 0.8741\n",
      "Epoch 1205/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0309 - acc: 0.9900 - val_loss: 3.4630 - val_acc: 0.8701\n",
      "Epoch 1206/2000\n",
      "625/625 [==============================] - 12s 16ms/step - loss: 0.0292 - acc: 0.9906 - val_loss: 2.7249 - val_acc: 0.8742\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=batched_dataset, validation_data=batched_val_dataset, callbacks=callbacks, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f3d217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e55ca7",
   "metadata": {},
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e72e3",
   "metadata": {},
   "source": [
    "## [Important] you should change your check point direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3ea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/home/michael1017/jinyu/comp4/ckpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5b7dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(base_path + 'x_test_cifar10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "443e7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fc3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524347ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8edcac61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc749ef7b80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2374e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.DataFrame()\n",
    "for i in range(x_test.shape[0]):\n",
    "    dic = {'id': int(i), 'label': y_pred[i]}\n",
    "    pre_df = pre_df.append(dic, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98d7af0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  label\n",
      "0  0.0    8.0\n",
      "1  1.0    8.0\n",
      "2  2.0    5.0\n",
      "3  3.0    2.0\n",
      "4  4.0    6.0\n",
      "5  5.0    7.0\n",
      "6  6.0    4.0\n",
      "7  7.0    0.0\n",
      "8  8.0    9.0\n",
      "9  9.0    3.0\n"
     ]
    }
   ],
   "source": [
    "print(pre_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a42d3e",
   "metadata": {},
   "source": [
    "## [Important] you should change your output csv direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eca348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pre_df.astype(int)\n",
    "pre_df.to_csv(\"/home/michael1017/work/data/comp4/cifar/origin/\" + \"cifar10_pred_202201190504.csv\", encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca60e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
